{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish-Abraham/PHQ9-Malayalam/blob/main/PHQ_9Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MISZsyoFyUEr",
        "outputId": "b33a62a3-bca4-41a0-c4e8-c48916d010ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PHQ9-Malayalam'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 14 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 1.27 MiB | 13.42 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ashish-Abraham/PHQ9-Malayalam.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnIYQOhN-v-_"
      },
      "source": [
        "# Emotion Tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4SvH1QY1m9I",
        "outputId": "aa6aa80c-7710-4f7e-f90e-8917a1d08584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tweet-preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo_MwaP3-0Wg"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyGg61zrRFCQ"
      },
      "outputs": [],
      "source": [
        "emotions = [\n",
        "    \"admiration\",\n",
        "    \"amusement\",\n",
        "    \"anger\",\n",
        "    \"annoyance\",\n",
        "    \"approval\",\n",
        "    \"caring\",\n",
        "    \"confusion\",\n",
        "    \"curiosity\",\n",
        "    \"desire\",\n",
        "    \"disappointment\",\n",
        "    \"disapproval\",\n",
        "    \"disgust\",\n",
        "    \"embarrassment\",\n",
        "    \"excitement\",\n",
        "    \"fear\",\n",
        "    \"gratitude\",\n",
        "    \"grief\",\n",
        "    \"joy\",\n",
        "    \"love\",\n",
        "    \"nervousness\",\n",
        "    \"optimism\",\n",
        "    \"pride\",\n",
        "    \"realization\",\n",
        "    \"relief\",\n",
        "    \"remorse\",\n",
        "    \"sadness\",\n",
        "    \"surprise\",\n",
        "    \"neutral\"\n",
        "]\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "INPUT_COLUMN = \"Do you feel tired or have little energy?\"\n",
        "INPUT_CSV = \"/content/PHQ9-Malayalam/psych_patient_emotion_data (1).csv\"\n",
        "OUTPUT_CSV = \"/content/Custom.xlsx\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm7pZFY3qeQq"
      },
      "outputs": [],
      "source": [
        "# # Read CSV\n",
        "import pandas as pd\n",
        "df_custom = pd.read_csv(INPUT_CSV, dtype=str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDJ1_lGT1sCD",
        "outputId": "acd1582f-c99c-4f72-a397-0c7600b452f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows created: 6\n",
            "                                                text       type  admiration  \\\n",
            "0  My appetite is all over the place; I either ov...   original           0   \n",
            "1  It's chaotic—some days I stuff myself, and oth...  augmented           0   \n",
            "2  I can't seem to find a middle ground with eati...  augmented           0   \n",
            "3  My eating habits are totally erratic, swinging...  augmented           0   \n",
            "4  It's frustrating because I have no control; I'...  augmented           0   \n",
            "5  I don't know what normal is anymore; I skip me...  augmented           0   \n",
            "\n",
            "   amusement  anger  annoyance  approval  caring  confusion  curiosity  ...  \\\n",
            "0          0      0          1         0       0          1          0  ...   \n",
            "1          0      0          1         0       0          1          0  ...   \n",
            "2          0      0          1         0       0          1          0  ...   \n",
            "3          0      0          1         0       0          1          0  ...   \n",
            "4          0      0          1         0       0          1          0  ...   \n",
            "5          0      0          1         0       0          1          0  ...   \n",
            "\n",
            "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
            "0     0            0         0      0            0       0        0        1   \n",
            "1     0            0         0      0            0       0        0        1   \n",
            "2     0            0         0      0            0       0        0        1   \n",
            "3     0            0         0      0            0       0        0        1   \n",
            "4     0            0         0      0            0       0        0        1   \n",
            "5     0            0         0      0            0       0        0        1   \n",
            "\n",
            "   surprise  neutral  \n",
            "0         0        0  \n",
            "1         0        0  \n",
            "2         0        0  \n",
            "3         0        0  \n",
            "4         0        0  \n",
            "5         0        0  \n",
            "\n",
            "[6 rows x 30 columns]\n",
            "File saved as 'psych_patient_emotion_data.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# 1. PASTE THE JSON OUTPUT FROM THE PREVIOUS STEP HERE\n",
        "# (I have included a small sample based on our previous turn for demonstration)\n",
        "json_data = [\n",
        "  {\n",
        "    \"original\": \"My appetite is all over the place; I either overeat or don’t eat at all.\",\n",
        "    \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "    \"rephrasings\": [\n",
        "      {\n",
        "        \"text\": \"It's chaotic—some days I stuff myself, and other days I can't look at food.\",\n",
        "        \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"I can't seem to find a middle ground with eating; it's always one extreme or the other.\",\n",
        "        \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"My eating habits are totally erratic, swinging between binging and starving.\",\n",
        "        \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"It's frustrating because I have no control; I'm either empty or too full.\",\n",
        "        \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "      },\n",
        "      {\n",
        "        \"text\": \"I don't know what normal is anymore; I skip meals or eat everything in sight.\",\n",
        "        \"emotion_labels\": [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "]\n",
        "\n",
        "# 3. Process the data to flatten the hierarchy\n",
        "processed_rows = []\n",
        "\n",
        "for entry in json_data:\n",
        "    # Add the Original text\n",
        "    row = {\n",
        "        \"text\": entry[\"original\"],\n",
        "        \"type\": \"original\",\n",
        "        \"label_vector\": entry[\"emotion_labels\"]\n",
        "    }\n",
        "    processed_rows.append(row)\n",
        "\n",
        "    # Add the Rephrasings (Augmented data)\n",
        "    for rephrasing in entry[\"rephrasings\"]:\n",
        "        row = {\n",
        "            \"text\": rephrasing[\"text\"],\n",
        "            \"type\": \"augmented\",\n",
        "            \"label_vector\": rephrasing[\"emotion_labels\"]\n",
        "        }\n",
        "        processed_rows.append(row)\n",
        "\n",
        "# 4. Create the DataFrame\n",
        "df = pd.DataFrame(processed_rows)\n",
        "\n",
        "# 5. Expand the 'label_vector' list into separate columns\n",
        "# This takes the list of 0s and 1s and maps them to the emotion names\n",
        "labels_df = pd.DataFrame(df['label_vector'].to_list(), columns=emotions)\n",
        "\n",
        "# Concatenate the text info with the emotion columns\n",
        "final_df = pd.concat([df[['text', 'type']], labels_df], axis=1)\n",
        "\n",
        "# 6. Display and Save\n",
        "print(f\"Total rows created: {len(final_df)}\")\n",
        "print(final_df)\n",
        "\n",
        "# Save to CSV\n",
        "final_df.to_csv(\"psych_patient_emotion_data.csv\", index=False)\n",
        "print(\"File saved as 'psych_patient_emotion_data.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "cf5999cc5a6a41a08a22f551b3440659",
            "f983539d6caa47feb069dad5f842a244",
            "41623073d2544d93992d69341794a691",
            "f56adec3d8a14e6b89fbe1999aef08e1",
            "1a3ba24b4c88433286023b4028297f88",
            "1545bd04df204a769e696d267865067b",
            "db87b99dcd5a4c0e934ada480264da00",
            "558e43b91ace4aa7a5e2fc95b3d32ab6",
            "c07091ca22fb4d229a893648ae1b7459",
            "bb8782032c2d4acdbbd067adff8ac42c",
            "8bdac28e05a840f4ba9c880d17595b0a",
            "d8496d91bdd94996890e059046761b2e",
            "bd7113db5ba04503bb1cb07af289e868",
            "a311dfcfee1e40cba1a35e68c4445a38",
            "0f31111641384c21a7512ab9e1084306",
            "e2c7f6c243d843898ef9190b769eb1c5",
            "928b8010e63f457c9b9adf4cccd982bb",
            "703caed3851149c9a1c7b161e467ffc7",
            "39cd82e864d34d67a9f0e551dba7ed7b",
            "457d9c7933bd4010b6e077e4bc031d6e",
            "71387bccb3e846e494a73735752d427f",
            "dac9dd532e79435ebfd77c0fae1dbea9",
            "f88dc793c2e64b1583b55f7ee4b58787",
            "516e3218c7b74db7bc97b42f502a9096",
            "14643316302f42e988caedb4e35e439c",
            "c55d09a17ba2488cb02b3244e43a79c1",
            "72100af067c4485cb7ba41fbd2421db0",
            "a9642c3cccbf4520b227e6f9d1379534",
            "32457585b0284f1ea4ec0bdb372ca30e",
            "cb88735f1a5c4c779dd10ce817eca640",
            "4aa499cb3ae64e42ad840b38fa87363f",
            "1ee96a0acd8d458f8e2304b1afa73f75",
            "1e191d02ca5242a7a6808a9c13e962f3"
          ]
        },
        "id": "LS0pkOqh9ZPQ",
        "outputId": "adb000a0-9669-44c2-fa37-92e26bfe2686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf5999cc5a6a41a08a22f551b3440659"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "goemotions.csv:   0%|          | 0.00/42.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8496d91bdd94996890e059046761b2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/211225 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f88dc793c2e64b1583b55f7ee4b58787"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"mrm8488/goemotions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dj7OvAvA8Ag",
        "outputId": "3237b44e-9fdf-44c3-8a97-933b62d94430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n",
              "        num_rows: 211225\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "bba0bf769a004003ae29a5632ce1949b",
            "0149aabc79cb4d6489e60e7d8898861e",
            "76e7de9c46084eeca3102dd898719277",
            "76ead1f0ba544d028f639d02f59f4d4e",
            "c065b013f74240d488ceac7067757116",
            "efa6bf0871924dbe824b3eabcea7c0a3",
            "a08d2e2f516c48a29e66377fd4724ebb",
            "1346aefaba514dfa9d09103d17d4535a",
            "4cda7bec0ff840e88cb7b0e6d519617b",
            "b68ce166e7a84f90a3621eeef2a3ca81",
            "ea632be7277a4bfe9443bdb1e28f872c"
          ]
        },
        "id": "eLloaS9gAz0G",
        "outputId": "d57c3b70-7e99-48db-fdfb-ea85902dcb4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/211225 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba0bf769a004003ae29a5632ce1949b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 211225\n",
            "Filtered dataset size: 207814\n",
            "Removed 3411 unclear examples\n"
          ]
        }
      ],
      "source": [
        "train_ds = ds['train']\n",
        "df_filtered = train_ds.filter(lambda example: example['example_very_unclear'] == False)\n",
        "\n",
        "# Alternative: you can also use the negation operator\n",
        "# df_filtered = train_ds.filter(lambda example: not example['example_very_unclear'])\n",
        "\n",
        "print(f\"Original dataset size: {len(train_ds)}\")\n",
        "print(f\"Filtered dataset size: {len(df_filtered)}\")\n",
        "print(f\"Removed {len(train_ds) - len(df_filtered)} unclear examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e42k7ZsF9WF"
      },
      "outputs": [],
      "source": [
        "emotion_columns = ['admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
        "                   'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
        "                   'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
        "                   'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',\n",
        "                   'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise',\n",
        "                   'neutral']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8dFjvqHF31x",
        "outputId": "61793684-18b2-46b6-b392-0e4530727c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution BEFORE balancing:\n",
            "neutral           55298\n",
            "approval          17620\n",
            "admiration        17131\n",
            "annoyance         13618\n",
            "gratitude         11625\n",
            "disapproval       11424\n",
            "curiosity          9692\n",
            "amusement          9245\n",
            "realization        8785\n",
            "optimism           8715\n",
            "disappointment     8469\n",
            "love               8191\n",
            "anger              8084\n",
            "joy                7983\n",
            "confusion          7359\n",
            "sadness            6758\n",
            "caring             5999\n",
            "excitement         5629\n",
            "surprise           5514\n",
            "disgust            5301\n",
            "desire             3817\n",
            "fear               3197\n",
            "remorse            2525\n",
            "embarrassment      2476\n",
            "nervousness        1810\n",
            "pride              1302\n",
            "relief             1289\n",
            "grief               673\n",
            "dtype: int64\n",
            "\n",
            "Total rows: 207814\n",
            "\n",
            "Balancing to minimum count: 673\n",
            "\n",
            "Label distribution AFTER balancing:\n",
            "admiration        1415\n",
            "approval          1284\n",
            "annoyance         1238\n",
            "gratitude         1174\n",
            "sadness           1162\n",
            "disappointment    1151\n",
            "optimism          1146\n",
            "joy               1078\n",
            "curiosity         1077\n",
            "realization       1076\n",
            "disapproval       1020\n",
            "love              1000\n",
            "anger              982\n",
            "amusement          956\n",
            "fear               936\n",
            "disgust            917\n",
            "caring             915\n",
            "confusion          908\n",
            "excitement         892\n",
            "surprise           854\n",
            "embarrassment      833\n",
            "desire             830\n",
            "nervousness        814\n",
            "remorse            794\n",
            "pride              723\n",
            "relief             701\n",
            "grief              673\n",
            "neutral            673\n",
            "dtype: int64\n",
            "\n",
            "Total rows after balancing: 18340\n",
            "Removed 189474 rows\n"
          ]
        }
      ],
      "source": [
        "df_filtered_pd = df_filtered.to_pandas()\n",
        "\n",
        "# Count positive labels for each emotion\n",
        "label_counts = df_filtered_pd[emotion_columns].sum()\n",
        "print(\"Label distribution BEFORE balancing:\")\n",
        "print(label_counts.sort_values(ascending=False))\n",
        "print(f\"\\nTotal rows: {len(df_filtered_pd)}\")\n",
        "\n",
        "# Step 2: Find minimum count to balance to\n",
        "min_count = label_counts.min()\n",
        "print(f\"\\nBalancing to minimum count: {min_count}\")\n",
        "\n",
        "# Step 3: Balance the dataset\n",
        "balanced_indices = []\n",
        "\n",
        "for emotion in emotion_columns:\n",
        "    # Get indices where this emotion is labeled as 1\n",
        "    emotion_indices = df_filtered_pd[df_filtered_pd[emotion] == 1].index.tolist()\n",
        "\n",
        "    # Randomly sample min_count indices\n",
        "    if len(emotion_indices) > min_count:\n",
        "        sampled_indices = np.random.choice(emotion_indices, size=min_count, replace=False)\n",
        "    else:\n",
        "        sampled_indices = emotion_indices\n",
        "\n",
        "    balanced_indices.extend(sampled_indices)\n",
        "\n",
        "# Remove duplicates and create balanced dataset\n",
        "balanced_indices = list(set(balanced_indices))\n",
        "df_filtered_balanced = df_filtered_pd.loc[balanced_indices].reset_index(drop=True)\n",
        "\n",
        "# Step 4: Verify balance\n",
        "label_counts_after = df_filtered_balanced[emotion_columns].sum()\n",
        "print(\"\\nLabel distribution AFTER balancing:\")\n",
        "print(label_counts_after.sort_values(ascending=False))\n",
        "print(f\"\\nTotal rows after balancing: {len(df_filtered_balanced)}\")\n",
        "print(f\"Removed {len(df_filtered_pd) - len(df_filtered_balanced)} rows\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFPgNmMIiAgd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from preprocessor import clean\n",
        "\n",
        "# Create spelling correction dictionary from common mistakes\n",
        "spelling_corrections = {\n",
        "    'dont': \"don't\", 'didnt': \"didn't\", 'doesnt': \"doesn't\", 'wont': \"won't\",\n",
        "    'cant': \"can't\", 'shouldnt': \"shouldn't\", 'wouldnt': \"wouldn't\",\n",
        "    'couldnt': \"couldn't\", 'isnt': \"isn't\", 'wasnt': \"wasn't\", 'werent': \"weren't\",\n",
        "    'havent': \"haven't\", 'hasnt': \"hasn't\", 'hadnt': \"hadn't\", 'youre': \"you're\",\n",
        "    'theyre': \"they're\", 'were': \"we're\", 'ive': \"I've\", 'youve': \"you've\",\n",
        "    'theyve': \"they've\", 'weve': \"we've\", 'im': \"I'm\", 'hes': \"he's\", 'shes': \"she's\",\n",
        "    'its': \"it's\", 'thats': \"that's\", 'whats': \"what's\", 'heres': \"here's\",\n",
        "    'theres': \"there's\", 'wheres': \"where's\", 'yall': \"y'all\", 'gonna': \"going to\",\n",
        "    'wanna': \"want to\", 'gotta': \"got to\", 'lemme': \"let me\", 'gimme': \"give me\",\n",
        "    'dunno': \"don't know\", 'kinda': \"kind of\", 'sorta': \"sort of\", 'lol': '',\n",
        "    'omg': '', 'wtf': '', 'tbh': '', 'imo': '', 'imho': ''\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove URLs, hashtags, emojis\n",
        "    text = clean(text)\n",
        "\n",
        "    # Fix UTF-8 encoding issues\n",
        "    text = text.replace('\\xe2\\x80\\x99', \"'\").replace('\\x27', \"'\")\n",
        "    text = text.replace('\\xe2\\x80\\x93', \"-\").replace('\\xe2\\x80\\x94', \"-\")\n",
        "\n",
        "    # Remove non-alphanumeric except punctuation\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,!?\\'\\\"-]', '', text)\n",
        "\n",
        "    # Fix spelling mistakes\n",
        "    words = text.split()\n",
        "    words = [spelling_corrections.get(word.lower(), word) for word in words]\n",
        "    text = ' '.join(words)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "df_filtered_balanced['text'] = df_filtered_balanced['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AF3bb1uh_Ig"
      },
      "outputs": [],
      "source": [
        "# Update df_filtered to use the balanced version\n",
        "df_filtered = df_filtered_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "tU58TApNHC1p",
        "outputId": "dcf4b91f-ae09-42a4-ac25-5ca088db1bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with more than one emotion labeled as 1: 7027\n",
            "Percentage: 38.32%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text       id  \\\n",
              "21                           Spice Burger. Delicious!  edgstis   \n",
              "22  I needed this laugh like... damn. This comment...  eeqd1yn   \n",
              "23  My year old sister is still creeped out by the...  eeeotpv   \n",
              "24  Honestly at this point I don't think there's a...  ee1pf1o   \n",
              "25                 Iunno, looks pretty Western to me.  eec67qc   \n",
              "\n",
              "                author     subreddit    link_id   parent_id   created_utc  \\\n",
              "21              oriain       ireland  t3_add4g1   t3_add4g1  1.546864e+09   \n",
              "22  mutualexasperation   breakingmom  t3_aiq20i  t1_eepovxn  1.548203e+09   \n",
              "23           MrFishpaw       netflix  t3_ahe81c   t3_ahe81c  1.547866e+09   \n",
              "24          GwenHarris  SuicideWatch  t3_aezjur  t1_edufjmd  1.547475e+09   \n",
              "25        ting_bu_dong         China  t3_ah6tpn  t1_eec65fa  1.547796e+09   \n",
              "\n",
              "    rater_id  example_very_unclear  admiration  ...  love  nervousness  \\\n",
              "21        61                 False           1  ...     0            0   \n",
              "22        72                 False           0  ...     1            0   \n",
              "23        57                 False           0  ...     0            0   \n",
              "24        42                 False           0  ...     0            1   \n",
              "25        37                 False           0  ...     0            0   \n",
              "\n",
              "    optimism  pride  realization  relief  remorse  sadness  surprise  neutral  \n",
              "21         0      0            0       0        0        0         0        0  \n",
              "22         0      0            0       0        0        0         1        0  \n",
              "23         0      0            0       0        0        0         0        0  \n",
              "24         0      0            1       0        0        0         0        0  \n",
              "25         0      0            1       0        0        0         0        0  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e210742-3b49-4926-97c3-999ab103eff7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>link_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>rater_id</th>\n",
              "      <th>example_very_unclear</th>\n",
              "      <th>admiration</th>\n",
              "      <th>...</th>\n",
              "      <th>love</th>\n",
              "      <th>nervousness</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pride</th>\n",
              "      <th>realization</th>\n",
              "      <th>relief</th>\n",
              "      <th>remorse</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Spice Burger. Delicious!</td>\n",
              "      <td>edgstis</td>\n",
              "      <td>oriain</td>\n",
              "      <td>ireland</td>\n",
              "      <td>t3_add4g1</td>\n",
              "      <td>t3_add4g1</td>\n",
              "      <td>1.546864e+09</td>\n",
              "      <td>61</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>I needed this laugh like... damn. This comment...</td>\n",
              "      <td>eeqd1yn</td>\n",
              "      <td>mutualexasperation</td>\n",
              "      <td>breakingmom</td>\n",
              "      <td>t3_aiq20i</td>\n",
              "      <td>t1_eepovxn</td>\n",
              "      <td>1.548203e+09</td>\n",
              "      <td>72</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>My year old sister is still creeped out by the...</td>\n",
              "      <td>eeeotpv</td>\n",
              "      <td>MrFishpaw</td>\n",
              "      <td>netflix</td>\n",
              "      <td>t3_ahe81c</td>\n",
              "      <td>t3_ahe81c</td>\n",
              "      <td>1.547866e+09</td>\n",
              "      <td>57</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Honestly at this point I don't think there's a...</td>\n",
              "      <td>ee1pf1o</td>\n",
              "      <td>GwenHarris</td>\n",
              "      <td>SuicideWatch</td>\n",
              "      <td>t3_aezjur</td>\n",
              "      <td>t1_edufjmd</td>\n",
              "      <td>1.547475e+09</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iunno, looks pretty Western to me.</td>\n",
              "      <td>eec67qc</td>\n",
              "      <td>ting_bu_dong</td>\n",
              "      <td>China</td>\n",
              "      <td>t3_ah6tpn</td>\n",
              "      <td>t1_eec65fa</td>\n",
              "      <td>1.547796e+09</td>\n",
              "      <td>37</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e210742-3b49-4926-97c3-999ab103eff7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e210742-3b49-4926-97c3-999ab103eff7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e210742-3b49-4926-97c3-999ab103eff7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0717eebd-1246-4afb-a706-d58966002b7d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0717eebd-1246-4afb-a706-d58966002b7d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0717eebd-1246-4afb-a706-d58966002b7d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rows_with_multiple"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Count how many rows have more than one emotion = 1\n",
        "multi_label_rows = (df_filtered_balanced[emotion_columns].sum(axis=1) > 1).sum()\n",
        "\n",
        "print(f\"Rows with more than one emotion labeled as 1: {multi_label_rows}\")\n",
        "percentage = multi_label_rows / len(df_filtered_balanced) * 100\n",
        "print(f\"Percentage: {percentage:.2f}%\")\n",
        "rows_with_multiple = df_filtered_balanced[df_filtered_balanced[emotion_columns].sum(axis=1) > 1]\n",
        "rows_with_multiple.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeDG2SenBj86",
        "outputId": "6647382d-2478-47b8-9503-5f264fff229f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom dataset size: 270\n",
            "GoEmotions clean size: 18340\n",
            "\n",
            "Column alignment check:\n",
            "Custom columns: ['text', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
            "GoEmotions columns: ['text', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
            "Columns match: True\n",
            "\n",
            "============================================================\n",
            "FINAL DATASET SIZES:\n",
            "============================================================\n",
            "Training set: 14888 samples\n",
            "  - From custom dataset: 216\n",
            "  - From GoEmotions: 14672\n",
            "\n",
            "Test set: 3722 samples\n",
            "  - From custom dataset: 54\n",
            "  - From GoEmotions: 3668\n",
            "============================================================\n",
            "\n",
            "Training set preview:\n",
            "                                                text admiration amusement  \\\n",
            "0  that's exactly me! Remembers all important con...          0         0   \n",
            "1  I might be a prude. \"Suck him off in the bathr...          0         0   \n",
            "2  You've been a sad boi around here for the last...          0         0   \n",
            "3  weeks or so' away from her kid for some 'alone...          0         0   \n",
            "4  Thank you! I suddenly see the benefits of Fahr...          0         0   \n",
            "\n",
            "  anger annoyance approval caring confusion curiosity desire  ... love  \\\n",
            "0     0         0        0      0         0         1      0  ...    0   \n",
            "1     1         0        0      0         0         0      0  ...    0   \n",
            "2     0         0        0      1         0         0      0  ...    0   \n",
            "3     0         0        0      0         0         0      0  ...    0   \n",
            "4     0         0        0      0         0         0      0  ...    0   \n",
            "\n",
            "  nervousness optimism pride realization relief remorse sadness surprise  \\\n",
            "0           0        0     0           1      0       0       0        0   \n",
            "1           0        0     0           0      0       0       0        0   \n",
            "2           0        0     0           0      0       0       1        0   \n",
            "3           0        0     0           0      0       1       0        0   \n",
            "4           0        0     0           1      0       0       0        0   \n",
            "\n",
            "  neutral  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "\n",
            "Test set preview:\n",
            "                                                text admiration amusement  \\\n",
            "0         I wouldn't announce that they are LuLaRoe.          0         0   \n",
            "1                             Hold on to your butts!          0         0   \n",
            "2     First and foremost you have to Love YOURSELF!!          0         0   \n",
            "3  Glad to see Tael wabi on the list but surprise...          0         0   \n",
            "4  I've actually taken this opportunity to get ba...          0         0   \n",
            "\n",
            "  anger annoyance approval caring confusion curiosity desire  ... love  \\\n",
            "0     0         1        0      0         0         0      0  ...    0   \n",
            "1     0         0        0      1         0         0      0  ...    0   \n",
            "2     0         0        0      0         0         0      0  ...    1   \n",
            "3     0         0        0      0         0         0      0  ...    0   \n",
            "4     0         0        0      0         0         0      0  ...    0   \n",
            "\n",
            "  nervousness optimism pride realization relief remorse sadness surprise  \\\n",
            "0           0        0     0           0      0       0       0        0   \n",
            "1           0        0     0           0      0       0       0        0   \n",
            "2           0        0     0           0      0       0       0        0   \n",
            "3           0        0     0           0      0       0       0        1   \n",
            "4           0        0     1           0      0       0       0        0   \n",
            "\n",
            "  neutral  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "columns_to_keep = ['text'] + emotion_columns\n",
        "\n",
        "# Keep only the relevant columns from GoEmotions\n",
        "df_goemotions_clean = df_filtered[columns_to_keep].copy()\n",
        "\n",
        "# Step 3: Ensure your custom dataset has the same column order\n",
        "df_custom_clean = df_custom[columns_to_keep].copy()\n",
        "\n",
        "print(f\"\\nCustom dataset size: {len(df_custom_clean)}\")\n",
        "print(f\"GoEmotions clean size: {len(df_goemotions_clean)}\")\n",
        "\n",
        "# Step 4: Verify column alignment\n",
        "print(\"\\nColumn alignment check:\")\n",
        "print(f\"Custom columns: {list(df_custom_clean.columns)}\")\n",
        "print(f\"GoEmotions columns: {list(df_goemotions_clean.columns)}\")\n",
        "print(f\"Columns match: {list(df_custom_clean.columns) == list(df_goemotions_clean.columns)}\")\n",
        "\n",
        "# Step 5: Train-test split for custom dataset (80-20 split)\n",
        "custom_train, custom_test = train_test_split(\n",
        "    df_custom_clean,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 6: Train-test split for GoEmotions dataset (80-20 split)\n",
        "goemotions_train, goemotions_test = train_test_split(\n",
        "    df_goemotions_clean,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 7: Combine the training sets\n",
        "train_combined = pd.concat([custom_train, goemotions_train], ignore_index=True)\n",
        "\n",
        "# Step 8: Combine the test sets\n",
        "test_combined = pd.concat([custom_test, goemotions_test], ignore_index=True)\n",
        "\n",
        "# Step 9: Shuffle the combined datasets\n",
        "train_combined = train_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_combined = test_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL DATASET SIZES:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training set: {len(train_combined)} samples\")\n",
        "print(f\"  - From custom dataset: {len(custom_train)}\")\n",
        "print(f\"  - From GoEmotions: {len(goemotions_train)}\")\n",
        "print(f\"\\nTest set: {len(test_combined)} samples\")\n",
        "print(f\"  - From custom dataset: {len(custom_test)}\")\n",
        "print(f\"  - From GoEmotions: {len(goemotions_test)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display first few rows of combined datasets\n",
        "print(\"\\nTraining set preview:\")\n",
        "print(train_combined.head())\n",
        "print(\"\\nTest set preview:\")\n",
        "print(test_combined.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJUuk1O-3to"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msosVwxUtOIQ"
      },
      "source": [
        "### MURIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802,
          "referenced_widgets": [
            "b15b627640834e0da88e475ed519642d",
            "97ce76198a044c6faf1ff02da6abf653",
            "f4d886d518db4c769b21d0ae21687e07",
            "936a71eec0704b8b969a9a381c1456e5",
            "25d6d91141e44ad3992be18f6bab26d6",
            "0597fbc601e34176aecaf13a2285d1df",
            "49146ea9eb654d53b130b0a0d56cab52",
            "ce568197436443ef8f62ebad874dc854",
            "9efc714fe3fb48faa39c848d656e4f6d",
            "a8badf7155c746439fd26f6a10cb1104",
            "fd658d2dbaea4b5690b3f3451f7ed522",
            "bca98e96acfe4dbabc1d08ebf259f679",
            "24d7812486824f77893a8cbe159d4da3",
            "6a528199762f43b68d888ef1cdeb671b",
            "4bfd1ab8aa74450885bcb92d70b5eeb8",
            "370ac141cbbb43309f08374796422ebc",
            "2680ec97ed444f759fbd0bc782df51a0",
            "6255eb232b0c4708b47c1a7f098e427a",
            "380974a7cb914658a08c936fab68f80e",
            "2da58f7b82154fb586b4e519802e290f",
            "3fbf76576004489d81cd38bcae8336e5",
            "042639933b8e49388bed02ebe0db8c00",
            "1970b04f125d4b1181732c9165d5f37b",
            "e98ed06bc4514f3fab02c738beb16c8c",
            "c86e273ab1de4706b2ea24b72bc8cde9",
            "c61ab01a81d7444b9b76ec292714d37f",
            "f43d1173141b42738c0ab85afc213476",
            "40903222ddcd4c5aab87103177c1cb27",
            "ca35089dc9c3475a97223e03bf3da74b",
            "64919fba2fc246ca99e8c9188d959c30",
            "59470828b28744319faf140424043b7b",
            "66640cd3e2844c3cbd759441990f682c",
            "606e3f202de2463f88016a5fa394dffa",
            "891b8499347e45fc95823c923480fe0a",
            "f09373f091c0498b8cdd2e10e6aeeb63",
            "560d670e55074cf3bcea53063668ac22",
            "2781542c38b240cf9c5a46111fae5bcf",
            "690566a3e7234ae68db4a81c65989be2",
            "a5e5ff04b7bd40be966833012899c80d",
            "df2bdf424ee347a38ce1543583e7de81",
            "d158a77b24c448d2b8d34a8724686624",
            "2b9e80c3ed3442eca3f539a853f62d23",
            "2fe4d1fe402b4eb980a6f052e95f71a6",
            "5cd541fccb794449b489d23471bc4bb9",
            "e2a9e8b2ca1f4bbea76fdc75823ae49e",
            "3e12f20e6d2c415f8e0aebefd66dcbef",
            "60fadf16bc0e48deaa8d4c1f50b0a77f",
            "58561ef2f3d74917a8dd1a2ecf51e813",
            "8bf4bc245c6e464894392b5c0d25d1d8",
            "cc0b3be5bdbe461ea29d445b9cfc5944",
            "bd80ffcbbba949528a0813b022de807e",
            "84040b32ed2a46698165158dc117d4a1",
            "26bffcae51ed4761a22d6597f265ce26",
            "ebb7cbb00fb445b1997d6cc3386c8527",
            "53dfb567c04e437c82e0758aac87892f",
            "545bd949cef54a48be54536fffacaa61",
            "9fc847d3f6f34de1936fca4488259a85",
            "167e8601f6834da9b254385dfd6521e9",
            "98cb29694be7400c99f46cfa8eb5b83c",
            "77972b5026804518ae2d5f51c659d4de",
            "4b58e1d640c94af1807e2dd07702f340",
            "779e04b27c004dcc8e2c178c5e4b46be",
            "51c9219170684369af10bf9856e7cbf3",
            "67bb65e3fdb04586967a5a65141235bb",
            "589b818830b04512bbe348f490d1ebb6",
            "afaf02a0409a41fb85d9d2afe94ec210"
          ]
        },
        "id": "DZt42rFssUhY",
        "outputId": "6aaa0d09-d600-4ade-a1f3-2b96526bc462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b15b627640834e0da88e475ed519642d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bca98e96acfe4dbabc1d08ebf259f679"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1970b04f125d4b1181732c9165d5f37b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "891b8499347e45fc95823c923480fe0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated pos_weights: tensor([12.1172, 18.1117, 17.6566, 13.2469, 13.1521], device='cuda:0')...\n",
            "Training samples: 14888\n",
            "Test samples: 3722\n",
            "\n",
            "Label distribution in training set:\n",
            "  admiration: 1135/14888 (7.6%)\n",
            "  amusement: 779/14888 (5.2%)\n",
            "  anger: 798/14888 (5.4%)\n",
            "  annoyance: 1045/14888 (7.0%)\n",
            "  approval: 1052/14888 (7.1%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2a9e8b2ca1f4bbea76fdc75823ae49e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/953M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "545bd949cef54a48be54536fffacaa61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model initialized with 237577756 parameters\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC: Initial Model Predictions (Before Training)\n",
            "============================================================\n",
            "\n",
            "Logits range: [-0.053, 0.053]\n",
            "Probabilities range: [0.487, 0.513]\n",
            "Mean probability: 0.500\n",
            "Predictions > 0.5: 104 out of 224\n",
            "✓ Encoder frozen - only classification head will be trained\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-244751029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m training_args_phase1 = TrainingArguments(\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./muril_emotion_phase1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Increased from 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# HYPERPARAMETER CHOICES - DETAILED EXPLANATION\n",
        "# ============================================================\n",
        "\"\"\"\n",
        "1. MODEL CHOICE: google/muril-base-cased\n",
        "   - Pre-trained on 17 Indian languages including Malayalam\n",
        "   - Better cross-lingual transfer than mBERT for Indian languages\n",
        "\n",
        "2. LEARNING RATE: 2e-5 (classification head), 1e-5 (encoder layers)\n",
        "   - Lower LR for encoder to preserve cross-lingual representations\n",
        "   - Higher LR for head since it's trained from scratch\n",
        "\n",
        "3. BATCH SIZE: 16 (with gradient accumulation steps = 2, effective = 32)\n",
        "   - Balanced for GPU memory and stable gradients\n",
        "   - Effective batch size 32 is optimal for transformer fine-tuning\n",
        "\n",
        "4. EPOCHS: 5-8\n",
        "   - Start with 5, use early stopping to prevent overfitting\n",
        "   - Cross-lingual transfer needs careful regularization\n",
        "\n",
        "5. WARMUP: 10% of training steps\n",
        "   - Gradual learning rate increase prevents destabilizing pre-trained weights\n",
        "\n",
        "6. WEIGHT DECAY: 0.01\n",
        "   - Regularization to maintain generalization to Malayalam\n",
        "\n",
        "7. DROPOUT: 0.3 (classification head)\n",
        "   - Higher dropout for regularization during cross-lingual transfer\n",
        "\n",
        "8. GRADIENT CLIPPING: 1.0\n",
        "   - Prevents exploding gradients with multi-label BCE loss\n",
        "\n",
        "9. FREEZING STRATEGY: Gradual unfreezing\n",
        "   - Phase 1: Freeze encoder, train classification head (2 epochs)\n",
        "   - Phase 2: Unfreeze top 4 encoder layers (3 epochs)\n",
        "   - Preserves cross-lingual knowledge while adapting to emotions\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "MURIL Fine-tuning for Multi-Label Emotion Classification - FIXED VERSION\n",
        "Addresses zero prediction issue with proper BCE loss and model architecture\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "MURIL Fine-tuning for Multi-Label Emotion Classification - FIXED VERSION\n",
        "Addresses zero prediction issue with proper BCE loss and model architecture\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 1. SETUP AND CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "MODEL_NAME = \"google/muril-base-cased\"\n",
        "NUM_LABELS = 28\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ============================================================\n",
        "# 2. PREPARE DATASETS WITH PROPER FORMATTING\n",
        "# ============================================================\n",
        "\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(label)  # Float for BCE loss\n",
        "        }\n",
        "\n",
        "# Prepare data\n",
        "train_texts = train_combined['text'].tolist()\n",
        "train_labels = train_combined[emotion_columns].values.astype(np.float32)\n",
        "\n",
        "test_texts = test_combined['text'].tolist()\n",
        "test_labels = test_combined[emotion_columns].values.astype(np.float32)\n",
        "\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Count positives per label\n",
        "num_positives = train_dataset.labels.sum(axis=0)\n",
        "num_samples = len(train_dataset)\n",
        "num_negatives = num_samples - num_positives\n",
        "# Calculate ratio: negatives / positives\n",
        "# If you have 10 positives and 90 negatives, weight should be 9.\n",
        "pos_weights = torch.tensor(num_negatives / num_positives)\n",
        "pos_weights = pos_weights.to(device) # Move to GPU\n",
        "print(f\"Calculated pos_weights: {pos_weights[:5]}...\") # Check values (should be > 1)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Check label distribution\n",
        "print(\"\\nLabel distribution in training set:\")\n",
        "for idx, emotion in enumerate(emotion_columns[:5]):  # Show first 5\n",
        "    pos_count = (train_labels[:, idx] == 1).sum()\n",
        "    print(f\"  {emotion}: {pos_count}/{len(train_labels)} ({pos_count/len(train_labels)*100:.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. FIXED MODEL ARCHITECTURE\n",
        "# ============================================================\n",
        "\n",
        "class MURILForMultiLabelClassification(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, pos_weights=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.pos_weights = pos_weights # Store weights\n",
        "        # Load MURIL base model\n",
        "        self.muril = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Classification head\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.muril.config.hidden_size, num_labels)\n",
        "\n",
        "        # Initialize classifier weights properly\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.zeros_(self.classifier.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Get MURIL outputs\n",
        "        outputs = self.muril(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Use [CLS] token representation\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Pass pos_weight to the loss function\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "model = MURILForMultiLabelClassification(MODEL_NAME, NUM_LABELS, pos_weights=pos_weights, dropout=0.3)\n",
        "model.to(device)\n",
        "\n",
        "print(f\"\\nModel initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. DIAGNOSTIC: Check Initial Predictions\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIAGNOSTIC: Initial Model Predictions (Before Training)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(torch.utils.data.DataLoader(train_dataset, batch_size=8)))\n",
        "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
        "    sample_attention_mask = sample_batch['attention_mask'].to(device)\n",
        "\n",
        "    outputs = model(sample_input_ids, sample_attention_mask)\n",
        "    sample_logits = outputs['logits']\n",
        "    sample_probs = torch.sigmoid(sample_logits)\n",
        "\n",
        "    print(f\"Logits range: [{sample_logits.min():.3f}, {sample_logits.max():.3f}]\")\n",
        "    print(f\"Probabilities range: [{sample_probs.min():.3f}, {sample_probs.max():.3f}]\")\n",
        "    print(f\"Mean probability: {sample_probs.mean():.3f}\")\n",
        "    print(f\"Predictions > 0.5: {(sample_probs > 0.5).sum().item()} out of {sample_probs.numel()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. FREEZING STRATEGY - PHASE 1\n",
        "# ============================================================\n",
        "\n",
        "def freeze_encoder(model):\n",
        "    \"\"\"Freeze MURIL encoder, keep classification head trainable\"\"\"\n",
        "    for param in model.muril.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Ensure classifier is trainable\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "    print(\"✓ Encoder frozen - only classification head will be trained\")\n",
        "\n",
        "def unfreeze_top_layers(model, num_layers=4):\n",
        "    \"\"\"Unfreeze top N encoder layers\"\"\"\n",
        "    total_layers = len(model.muril.encoder.layer)\n",
        "    for i in range(total_layers - num_layers, total_layers):\n",
        "        for param in model.muril.encoder.layer[i].parameters():\n",
        "            param.requires_grad = True\n",
        "    print(f\"✓ Top {num_layers} encoder layers unfrozen\")\n",
        "\n",
        "freeze_encoder(model)\n",
        "\n",
        "# ============================================================\n",
        "# 6. IMPROVED METRICS WITH DEBUGGING\n",
        "# ============================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probs = 1 / (1 + np.exp(-logits))  # Sigmoid\n",
        "    predictions = (probs > 0.5).astype(int)\n",
        "\n",
        "    # Debug: Check prediction distribution\n",
        "    num_positives = predictions.sum()\n",
        "    total_predictions = predictions.size\n",
        "\n",
        "    # Multi-label metrics\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "    exact_match = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Additional diagnostic metrics\n",
        "    avg_labels_per_sample = labels.sum(axis=1).mean()\n",
        "    avg_predictions_per_sample = predictions.sum(axis=1).mean()\n",
        "\n",
        "    return {\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'hamming_loss': hamming,\n",
        "        'exact_match': exact_match,\n",
        "        'num_positive_preds': num_positives,\n",
        "        'avg_labels_per_sample': avg_labels_per_sample,\n",
        "        'avg_preds_per_sample': avg_predictions_per_sample\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 7. PHASE 1 TRAINING - WITH BETTER HYPERPARAMETERS\n",
        "# ============================================================\n",
        "\n",
        "training_args_phase1 = TrainingArguments(\n",
        "    output_dir='./muril_emotion_phase1',\n",
        "    num_train_epochs=3,  # Increased from 2\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-3,  # Changed from 1e-3 to 5e-5\n",
        "    weight_decay=0.05,\n",
        "    warmup_ratio=0.15,\n",
        "    logging_dir='./logs_phase1',\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1_macro',\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_num_workers=2,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    label_smoothing_factor=0.0  # No label smoothing for multi-label\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1: Training Classification Head (Encoder Frozen)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "trainer_phase1 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_phase1,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")\n",
        "\n",
        "trainer_phase1.train()\n",
        "\n",
        "# Evaluate Phase 1\n",
        "phase1_results = trainer_phase1.evaluate()\n",
        "print(\"\\nPhase 1 Results:\")\n",
        "for key, value in phase1_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. CHECK IF MODEL IS LEARNING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POST-PHASE 1 DIAGNOSTIC\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(torch.utils.data.DataLoader(test_dataset, batch_size=8)))\n",
        "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
        "    sample_attention_mask = sample_batch['attention_mask'].to(device)\n",
        "    sample_labels = sample_batch['labels']\n",
        "\n",
        "    outputs = model(sample_input_ids, sample_attention_mask)\n",
        "    sample_logits = outputs['logits']\n",
        "    sample_probs = torch.sigmoid(sample_logits)\n",
        "\n",
        "    print(f\"Logits range: [{sample_logits.min():.3f}, {sample_logits.max():.3f}]\")\n",
        "    print(f\"Probabilities range: [{sample_probs.min():.3f}, {sample_probs.max():.3f}]\")\n",
        "    print(f\"Mean probability: {sample_probs.mean():.3f}\")\n",
        "    print(f\"Predictions > 0.5: {(sample_probs > 0.5).sum().item()} out of {sample_probs.numel()}\")\n",
        "    print(f\"Actual positive labels: {sample_labels.sum().item()}\")\n",
        "\n",
        "# Only continue to Phase 2 if model is learning\n",
        "if phase1_results['eval_f1_macro'] > 0.01:\n",
        "    print(\"\\n✓ Model is learning! Proceeding to Phase 2...\")\n",
        "\n",
        "    # ============================================================\n",
        "    # 9. PHASE 2 - UNFREEZE TOP LAYERS\n",
        "    # ============================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 2: Fine-tuning Top Encoder Layers\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    unfreeze_top_layers(model, num_layers=4)\n",
        "\n",
        "    training_args_phase2 = TrainingArguments(\n",
        "        output_dir='./muril_emotion_phase2',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=32,\n",
        "        gradient_accumulation_steps=2,\n",
        "        learning_rate=2e-5,\n",
        "        weight_decay=0.05,\n",
        "        warmup_ratio=0.15,\n",
        "        max_grad_norm=1.0,\n",
        "        logging_dir='./logs_phase2',\n",
        "        logging_steps=50,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=200,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1_macro',\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=2,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    trainer_phase2 = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_phase2,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    )\n",
        "\n",
        "    trainer_phase2.train()\n",
        "    final_results = trainer_phase2.evaluate()\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠ WARNING: Model not learning in Phase 1!\")\n",
        "    print(\"Skipping Phase 2. Need to debug further.\")\n",
        "    final_results = phase1_results\n",
        "\n",
        "# ============================================================\n",
        "# 10. FINAL EVALUATION WITH ADAPTIVE THRESHOLD\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL EVALUATION WITH ADAPTIVE THRESHOLD\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Try different thresholds to find optimal\n",
        "model.eval()\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in torch.utils.data.DataLoader(test_dataset, batch_size=32):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        all_logits.append(outputs['logits'].cpu())\n",
        "        all_labels.append(batch['labels'])\n",
        "\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "all_probs = torch.sigmoid(all_logits).numpy()\n",
        "all_labels = all_labels.numpy()\n",
        "\n",
        "# Test different thresholds\n",
        "print(\"Testing different prediction thresholds:\")\n",
        "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    preds = (all_probs > threshold).astype(int)\n",
        "    f1_macro = f1_score(all_labels, preds, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(all_labels, preds, average='micro', zero_division=0)\n",
        "    avg_preds = preds.sum() / len(preds)\n",
        "    print(f\"  Threshold {threshold:.1f} - F1 Macro: {f1_macro:.4f}, F1 Micro: {f1_micro:.4f}, Avg preds/sample: {avg_preds:.2f}\")\n",
        "\n",
        "# Use best threshold\n",
        "best_threshold = 0.5\n",
        "pred_labels = (all_probs > best_threshold).astype(int)\n",
        "\n",
        "print(f\"\\nUsing threshold: {best_threshold}\")\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"  F1 Macro:     {f1_score(all_labels, pred_labels, average='macro', zero_division=0):.4f}\")\n",
        "print(f\"  F1 Micro:     {f1_score(all_labels, pred_labels, average='micro', zero_division=0):.4f}\")\n",
        "print(f\"  F1 Weighted:  {f1_score(all_labels, pred_labels, average='weighted', zero_division=0):.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_loss(all_labels, pred_labels):.4f}\")\n",
        "print(f\"  Exact Match:  {accuracy_score(all_labels, pred_labels):.4f}\")\n",
        "\n",
        "# Per-emotion performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-EMOTION PERFORMANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    f1 = f1_score(all_labels[:, idx], pred_labels[:, idx], zero_division=0)\n",
        "    support = all_labels[:, idx].sum()\n",
        "    avg_prob = all_probs[:, idx].mean()\n",
        "    print(f\"{emotion:15s} - F1: {f1:.4f}, Support: {int(support):4d}, Avg Prob: {avg_prob:.3f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 11. SAVE MODEL\n",
        "# ============================================================\n",
        "# Save the underlying MURIL model (feature extractor) separately\n",
        "# so it can be loaded by AutoModel.from_pretrained in the next step.\n",
        "model.muril.save_pretrained('./muril_emotion_final')\n",
        "\n",
        "# Save the tokenizer, which is associated with the MURIL model\n",
        "tokenizer.save_pretrained('./muril_emotion_final')\n",
        "\n",
        "# If the classification head's weights are also needed later, save its state_dict\n",
        "# The current plan is to use XGBoost, so this might be optional for the current flow,\n",
        "# but good practice for full model recovery.\n",
        "torch.save(model.classifier.state_dict(), './muril_emotion_final/classifier_head.pt')\n",
        "\n",
        "print(\"\\n✓ MURIL feature extractor and tokenizer saved to './muril_emotion_final'\")\n",
        "print(\"✓ Classification head state_dict saved to './muril_emotion_final/classifier_head.pt'\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16KbOakzMg1C"
      },
      "source": [
        "Without Freezing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVPrdWsL11Fh",
        "outputId": "835999e3-c4da-4b60-d862-d7f492f04865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Training samples: 14897\n",
            "Test samples: 3725\n",
            "\n",
            "Label frequencies (train):\n",
            "  admiration     : 1119 (7.51%)\n",
            "  amusement      : 779 (5.23%)\n",
            "  anger          : 758 (5.09%)\n",
            "  annoyance      : 1031 (6.92%)\n",
            "  approval       : 1072 (7.20%)\n",
            "  caring         : 775 (5.20%)\n",
            "  confusion      : 767 (5.15%)\n",
            "  curiosity      : 868 (5.83%)\n",
            "  desire         : 668 (4.48%)\n",
            "  disappointment : 1028 (6.90%)\n",
            "  disapproval    : 824 (5.53%)\n",
            "  disgust        : 738 (4.95%)\n",
            "  embarrassment  : 670 (4.50%)\n",
            "  excitement     : 745 (5.00%)\n",
            "  fear           : 710 (4.77%)\n",
            "  gratitude      : 931 (6.25%)\n",
            "  grief          : 563 (3.78%)\n",
            "  joy            : 867 (5.82%)\n",
            "  love           : 777 (5.22%)\n",
            "  nervousness    : 686 (4.60%)\n",
            "  optimism       : 955 (6.41%)\n",
            "  pride          : 578 (3.88%)\n",
            "  realization    : 908 (6.10%)\n",
            "  relief         : 599 (4.02%)\n",
            "  remorse        : 642 (4.31%)\n",
            "  sadness        : 1064 (7.14%)\n",
            "  surprise       : 699 (4.69%)\n",
            "  neutral        : 575 (3.86%)\n",
            "\n",
            "pos_weight per label (clipped):\n",
            "  admiration     : 10.00\n",
            "  amusement      : 10.00\n",
            "  anger          : 10.00\n",
            "  annoyance      : 10.00\n",
            "  approval       : 10.00\n",
            "  caring         : 10.00\n",
            "  confusion      : 10.00\n",
            "  curiosity      : 10.00\n",
            "  desire         : 10.00\n",
            "  disappointment : 10.00\n",
            "  disapproval    : 10.00\n",
            "  disgust        : 10.00\n",
            "  embarrassment  : 10.00\n",
            "  excitement     : 10.00\n",
            "  fear           : 10.00\n",
            "  gratitude      : 10.00\n",
            "  grief          : 10.00\n",
            "  joy            : 10.00\n",
            "  love           : 10.00\n",
            "  nervousness    : 10.00\n",
            "  optimism       : 10.00\n",
            "  pride          : 10.00\n",
            "  realization    : 10.00\n",
            "  relief         : 10.00\n",
            "  remorse        : 10.00\n",
            "  sadness        : 10.00\n",
            "  surprise       : 10.00\n",
            "  neutral        : 10.00\n",
            "\n",
            "Model initialized: 237,577,756 params (237,577,756 trainable)\n",
            "\n",
            "===============================\n",
            "TRAINING MURIL (FULL FINETUNE)\n",
            "===============================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2330' max='2330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2330/2330 38:46, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>Avg Labels Per Sample</th>\n",
              "      <th>Avg Preds Per Sample</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.997400</td>\n",
              "      <td>0.997319</td>\n",
              "      <td>0.101350</td>\n",
              "      <td>0.032694</td>\n",
              "      <td>0.040173</td>\n",
              "      <td>0.064439</td>\n",
              "      <td>0.005369</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>0.509530</td>\n",
              "      <td>5.994300</td>\n",
              "      <td>621.423000</td>\n",
              "      <td>19.519000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>0.967059</td>\n",
              "      <td>0.226364</td>\n",
              "      <td>0.143578</td>\n",
              "      <td>0.160070</td>\n",
              "      <td>0.104660</td>\n",
              "      <td>0.021745</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>2.289664</td>\n",
              "      <td>6.045900</td>\n",
              "      <td>616.117000</td>\n",
              "      <td>19.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.946300</td>\n",
              "      <td>0.942223</td>\n",
              "      <td>0.260217</td>\n",
              "      <td>0.213539</td>\n",
              "      <td>0.227455</td>\n",
              "      <td>0.131381</td>\n",
              "      <td>0.009128</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.474362</td>\n",
              "      <td>5.942000</td>\n",
              "      <td>626.895000</td>\n",
              "      <td>19.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.925400</td>\n",
              "      <td>0.918990</td>\n",
              "      <td>0.295105</td>\n",
              "      <td>0.259081</td>\n",
              "      <td>0.269337</td>\n",
              "      <td>0.114324</td>\n",
              "      <td>0.014228</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.042953</td>\n",
              "      <td>5.927100</td>\n",
              "      <td>628.472000</td>\n",
              "      <td>19.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.905400</td>\n",
              "      <td>0.899415</td>\n",
              "      <td>0.306131</td>\n",
              "      <td>0.293282</td>\n",
              "      <td>0.298135</td>\n",
              "      <td>0.114046</td>\n",
              "      <td>0.012617</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.103893</td>\n",
              "      <td>6.082500</td>\n",
              "      <td>612.409000</td>\n",
              "      <td>19.235000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.880800</td>\n",
              "      <td>0.883122</td>\n",
              "      <td>0.312807</td>\n",
              "      <td>0.311083</td>\n",
              "      <td>0.311763</td>\n",
              "      <td>0.122081</td>\n",
              "      <td>0.014228</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.475973</td>\n",
              "      <td>6.052000</td>\n",
              "      <td>615.494000</td>\n",
              "      <td>19.332000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.860100</td>\n",
              "      <td>0.868633</td>\n",
              "      <td>0.336108</td>\n",
              "      <td>0.328288</td>\n",
              "      <td>0.329828</td>\n",
              "      <td>0.104765</td>\n",
              "      <td>0.023893</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>2.920268</td>\n",
              "      <td>5.936800</td>\n",
              "      <td>627.444000</td>\n",
              "      <td>19.708000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.842900</td>\n",
              "      <td>0.859172</td>\n",
              "      <td>0.339095</td>\n",
              "      <td>0.332735</td>\n",
              "      <td>0.333938</td>\n",
              "      <td>0.107785</td>\n",
              "      <td>0.023356</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.068188</td>\n",
              "      <td>6.029000</td>\n",
              "      <td>617.844000</td>\n",
              "      <td>19.406000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.846900</td>\n",
              "      <td>0.850843</td>\n",
              "      <td>0.341683</td>\n",
              "      <td>0.338826</td>\n",
              "      <td>0.339987</td>\n",
              "      <td>0.105331</td>\n",
              "      <td>0.032483</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>2.981745</td>\n",
              "      <td>6.175300</td>\n",
              "      <td>603.208000</td>\n",
              "      <td>18.946000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.836500</td>\n",
              "      <td>0.846818</td>\n",
              "      <td>0.340470</td>\n",
              "      <td>0.339042</td>\n",
              "      <td>0.339808</td>\n",
              "      <td>0.109578</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.153826</td>\n",
              "      <td>6.067100</td>\n",
              "      <td>613.963000</td>\n",
              "      <td>19.284000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.830300</td>\n",
              "      <td>0.843292</td>\n",
              "      <td>0.341433</td>\n",
              "      <td>0.341904</td>\n",
              "      <td>0.342033</td>\n",
              "      <td>0.109923</td>\n",
              "      <td>0.028725</td>\n",
              "      <td>1.498255</td>\n",
              "      <td>3.175302</td>\n",
              "      <td>6.131100</td>\n",
              "      <td>607.559000</td>\n",
              "      <td>19.083000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best checkpoint metrics:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [117/117 00:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  eval_loss: 0.8433\n",
            "  eval_f1_micro: 0.3414\n",
            "  eval_f1_macro: 0.3419\n",
            "  eval_f1_weighted: 0.3420\n",
            "  eval_hamming_loss: 0.1099\n",
            "  eval_exact_match: 0.0287\n",
            "  eval_avg_labels_per_sample: 1.4983\n",
            "  eval_avg_preds_per_sample: 3.1753\n",
            "  eval_runtime: 6.2643\n",
            "  eval_samples_per_second: 594.6420\n",
            "  eval_steps_per_second: 18.6770\n",
            "  epoch: 5.0000\n",
            "\n",
            "========================================\n",
            "FINAL EVALUATION WITH THRESHOLD SWEEP\n",
            "========================================\n",
            "\n",
            "Threshold sweep (global):\n",
            "  thr=0.3 -> F1_macro=0.1094, F1_micro=0.1089, avg preds/sample=25.72\n",
            "  thr=0.4 -> F1_macro=0.2199, F1_micro=0.2019, avg preds/sample=10.71\n",
            "  thr=0.5 -> F1_macro=0.3419, F1_micro=0.3414, avg preds/sample=3.18\n",
            "  thr=0.6 -> F1_macro=0.2210, F1_micro=0.2994, avg preds/sample=0.67\n",
            "  thr=0.7 -> F1_macro=0.0587, F1_micro=0.0954, avg preds/sample=0.10\n",
            "\n",
            "Chosen threshold: 0.50 (best macro F1 = 0.3419)\n",
            "\n",
            "Final metrics with chosen threshold:\n",
            "  F1 Macro:     0.3419\n",
            "  F1 Micro:     0.3414\n",
            "  F1 Weighted:  0.3420\n",
            "  Hamming Loss: 0.1099\n",
            "  Exact Match:  0.0287\n",
            "\n",
            "===============================\n",
            "PER-EMOTION DIAGNOSTICS\n",
            "===============================\n",
            "\n",
            "admiration      | F1: 0.3639 | support:  280 | avg_prob: 0.428\n",
            "amusement       | F1: 0.3051 | support:  191 | avg_prob: 0.401\n",
            "anger           | F1: 0.3123 | support:  198 | avg_prob: 0.396\n",
            "annoyance       | F1: 0.2801 | support:  254 | avg_prob: 0.443\n",
            "approval        | F1: 0.2408 | support:  290 | avg_prob: 0.457\n",
            "caring          | F1: 0.2734 | support:  168 | avg_prob: 0.407\n",
            "confusion       | F1: 0.3779 | support:  186 | avg_prob: 0.377\n",
            "curiosity       | F1: 0.4411 | support:  209 | avg_prob: 0.398\n",
            "desire          | F1: 0.3708 | support:  163 | avg_prob: 0.369\n",
            "disappointment  | F1: 0.2527 | support:  257 | avg_prob: 0.446\n",
            "disapproval     | F1: 0.3092 | support:  225 | avg_prob: 0.418\n",
            "disgust         | F1: 0.3196 | support:  183 | avg_prob: 0.389\n",
            "embarrassment   | F1: 0.2072 | support:  137 | avg_prob: 0.366\n",
            "excitement      | F1: 0.3250 | support:  194 | avg_prob: 0.391\n",
            "fear            | F1: 0.4597 | support:  217 | avg_prob: 0.378\n",
            "gratitude       | F1: 0.6854 | support:  230 | avg_prob: 0.358\n",
            "grief           | F1: 0.4195 | support:  134 | avg_prob: 0.353\n",
            "joy             | F1: 0.3392 | support:  213 | avg_prob: 0.386\n",
            "love            | F1: 0.5969 | support:  190 | avg_prob: 0.359\n",
            "nervousness     | F1: 0.2826 | support:  159 | avg_prob: 0.376\n",
            "optimism        | F1: 0.3041 | support:  233 | avg_prob: 0.434\n",
            "pride           | F1: 0.2997 | support:  144 | avg_prob: 0.382\n",
            "realization     | F1: 0.0858 | support:  231 | avg_prob: 0.435\n",
            "relief          | F1: 0.3526 | support:  142 | avg_prob: 0.364\n",
            "remorse         | F1: 0.6166 | support:  169 | avg_prob: 0.349\n",
            "sadness         | F1: 0.3520 | support:  261 | avg_prob: 0.429\n",
            "surprise        | F1: 0.4000 | support:  171 | avg_prob: 0.385\n",
            "neutral         | F1: 0.0000 | support:  152 | avg_prob: 0.375\n",
            "\n",
            "Saved encoder + tokenizer + classifier head in './muril_emotion_sota/final_export'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss\n",
        "import torch.nn as nn\n",
        "\n",
        "# ============================================================\n",
        "# 0. BASIC CONFIG\n",
        "# ============================================================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "MODEL_NAME = \"google/muril-base-cased\"\n",
        "NUM_LABELS = len(emotion_columns)\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ============================================================\n",
        "# 1. DATASET WRAPPER\n",
        "# ============================================================\n",
        "\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, text_col, label_cols, tokenizer, max_length):\n",
        "        self.texts = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_cols].astype(np.float32).values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.float),\n",
        "        }\n",
        "\n",
        "train_dataset = EmotionDataset(\n",
        "    df=train_combined,\n",
        "    text_col=\"text\",\n",
        "    label_cols=emotion_columns,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_LENGTH,\n",
        ")\n",
        "\n",
        "test_dataset = EmotionDataset(\n",
        "    df=test_combined,\n",
        "    text_col=\"text\",\n",
        "    label_cols=emotion_columns,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=MAX_LENGTH,\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Label stats\n",
        "train_labels_np = train_combined[emotion_columns].astype(np.float32).values\n",
        "label_freq = train_labels_np.sum(axis=0)\n",
        "print(\"\\nLabel frequencies (train):\")\n",
        "for e, c in zip(emotion_columns, label_freq):\n",
        "    print(f\"  {e:15s}: {int(c)} ({c/len(train_dataset)*100:.2f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. CLASS IMBALANCE HANDLING (pos_weight)\n",
        "# ============================================================\n",
        "\n",
        "num_samples = len(train_dataset)\n",
        "num_positives = label_freq\n",
        "num_negatives = num_samples - num_positives\n",
        "\n",
        "eps = 1e-6\n",
        "raw_pos_weights = num_negatives / (num_positives + eps)\n",
        "\n",
        "max_pos_weight = 10.0\n",
        "pos_weights = np.clip(raw_pos_weights, 1.0, max_pos_weight)\n",
        "pos_weights = torch.tensor(pos_weights, dtype=torch.float, device=device)\n",
        "\n",
        "print(\"\\npos_weight per label (clipped):\")\n",
        "for e, w in zip(emotion_columns, pos_weights.cpu().numpy()):\n",
        "    print(f\"  {e:15s}: {w:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. MODEL: MURIL + CLASSIFIER HEAD\n",
        "# ============================================================\n",
        "\n",
        "class MURILForMultiLabel(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, pos_weights, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.pos_weights = pos_weights\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.zeros_(self.classifier.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "        )\n",
        "        pooled = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled = self.dropout(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "model = MURILForMultiLabel(\n",
        "    model_name=MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    pos_weights=pos_weights,\n",
        "    dropout=0.3,\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nModel initialized: {total_params:,} params ({trainable_params:,} trainable)\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. METRICS\n",
        "# ============================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = 1.0 / (1.0 + np.exp(-logits))  # sigmoid\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    f1_micro = f1_score(labels, preds, average=\"micro\", zero_division=0)\n",
        "    f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\", zero_division=0)\n",
        "    hamming = hamming_loss(labels, preds)\n",
        "    exact_match = accuracy_score(labels, preds)\n",
        "\n",
        "    avg_labels_per_sample = labels.sum(axis=1).mean()\n",
        "    avg_preds_per_sample = preds.sum(axis=1).mean()\n",
        "\n",
        "    return {\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"hamming_loss\": hamming,\n",
        "        \"exact_match\": exact_match,\n",
        "        \"avg_labels_per_sample\": avg_labels_per_sample,\n",
        "        \"avg_preds_per_sample\": avg_preds_per_sample,\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 5. TRAINING ARGS (use eval_strategy to match your version)\n",
        "# ============================================================\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./muril_emotion_sota\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    max_grad_norm=1.0,\n",
        "    logging_dir=\"./logs_muril_emotion\",\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",      # IMPORTANT: your transformers uses eval_strategy\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_num_workers=2,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 6. TRAIN\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n===============================\")\n",
        "print(\"TRAINING MURIL (FULL FINETUNE)\")\n",
        "print(\"===============================\\n\")\n",
        "\n",
        "train_result = trainer.train()\n",
        "trainer.save_model(\"./muril_emotion_sota/best_model\")\n",
        "\n",
        "print(\"\\nBest checkpoint metrics:\")\n",
        "best_metrics = trainer.evaluate()\n",
        "for k, v in best_metrics.items():\n",
        "    if isinstance(v, float):\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. FINAL EVAL WITH THRESHOLD SWEEP\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n========================================\")\n",
        "print(\"FINAL EVALUATION WITH THRESHOLD SWEEP\")\n",
        "print(\"========================================\\n\")\n",
        "\n",
        "model.eval()\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=32, shuffle=False\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        all_logits.append(outputs[\"logits\"].cpu())\n",
        "        all_labels.append(labels)\n",
        "\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "all_probs = torch.sigmoid(all_logits).numpy()\n",
        "all_labels_np = all_labels.numpy()\n",
        "\n",
        "best_macro = -1.0\n",
        "best_threshold = 0.5\n",
        "\n",
        "print(\"Threshold sweep (global):\")\n",
        "for thr in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    preds = (all_probs > thr).astype(int)\n",
        "    f1_macro = f1_score(all_labels_np, preds, average=\"macro\", zero_division=0)\n",
        "    f1_micro = f1_score(all_labels_np, preds, average=\"micro\", zero_division=0)\n",
        "    avg_preds = preds.sum(axis=1).mean()\n",
        "    print(\n",
        "        f\"  thr={thr:.1f} -> \"\n",
        "        f\"F1_macro={f1_macro:.4f}, F1_micro={f1_micro:.4f}, \"\n",
        "        f\"avg preds/sample={avg_preds:.2f}\"\n",
        "    )\n",
        "    if f1_macro > best_macro:\n",
        "        best_macro = f1_macro\n",
        "        best_threshold = thr\n",
        "\n",
        "print(f\"\\nChosen threshold: {best_threshold:.2f} (best macro F1 = {best_macro:.4f})\")\n",
        "\n",
        "final_preds = (all_probs > best_threshold).astype(int)\n",
        "\n",
        "print(\"\\nFinal metrics with chosen threshold:\")\n",
        "print(\n",
        "    f\"  F1 Macro:     \"\n",
        "    f\"{f1_score(all_labels_np, final_preds, average='macro', zero_division=0):.4f}\"\n",
        ")\n",
        "print(\n",
        "    f\"  F1 Micro:     \"\n",
        "    f\"{f1_score(all_labels_np, final_preds, average='micro', zero_division=0):.4f}\"\n",
        ")\n",
        "print(\n",
        "    f\"  F1 Weighted:  \"\n",
        "    f\"{f1_score(all_labels_np, final_preds, average='weighted', zero_division=0):.4f}\"\n",
        ")\n",
        "print(f\"  Hamming Loss: {hamming_loss(all_labels_np, final_preds):.4f}\")\n",
        "print(f\"  Exact Match:  {accuracy_score(all_labels_np, final_preds):.4f}\")\n",
        "\n",
        "print(\"\\n===============================\")\n",
        "print(\"PER-EMOTION DIAGNOSTICS\")\n",
        "print(\"===============================\\n\")\n",
        "\n",
        "for i, emotion in enumerate(emotion_columns):\n",
        "    f1_e = f1_score(all_labels_np[:, i], final_preds[:, i], zero_division=0)\n",
        "    support = int(all_labels_np[:, i].sum())\n",
        "    avg_prob = all_probs[:, i].mean()\n",
        "    print(\n",
        "        f\"{emotion:15s} | F1: {f1_e:.4f} | \"\n",
        "        f\"support: {support:4d} | avg_prob: {avg_prob:.3f}\"\n",
        "    )\n",
        "\n",
        "# ============================================================\n",
        "# 8. SAVE ENCODER + TOKENIZER + HEAD\n",
        "# ============================================================\n",
        "\n",
        "save_dir = \"./muril_emotion_sota/final_export\"\n",
        "model.encoder.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "torch.save(model.classifier.state_dict(), f\"{save_dir}/classifier_head.pt\")\n",
        "\n",
        "print(f\"\\nSaved encoder + tokenizer + classifier head in '{save_dir}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEZujHCT11pg"
      },
      "source": [
        "### MURIL + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2c68142t1s6d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from xgboost import XGBClassifier # Removed 'callback' as it's not needed with direct args\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, classification_report\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG / PATHS\n",
        "# -------------------------------------------------------------------\n",
        "MODEL_PATH = './muril_emotion_final'  # folder you saved: contains tokenizer + base model\n",
        "CLASSIFIER_HEAD_PATH = os.path.join(MODEL_PATH, 'classifier_head.pt')  # optional\n",
        "EMBED_MAX_LENGTH = 128\n",
        "BATCH_SIZE_FE = 32\n",
        "\n",
        "# Ensure these variables are available in this scope:\n",
        "# - train_combined, test_combined, emotion_columns\n",
        "# (They were defined in your training script. If not, load them here.)\n",
        "\n",
        "NUM_LABELS = len(emotion_columns)\n",
        "\n",
        "# ============================================================\n",
        "# 1. LOAD SAVED TOKENIZER + FEATURE EXTRACTOR (MURIL)\n",
        "# ============================================================\n",
        "print(\"Loading tokenizer from original model name and MURIL feature extractor from:\", MODEL_PATH)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) # Load tokenizer from original name\n",
        "\n",
        "# Load encoder-only (AutoModel) from the saved folder\n",
        "feature_extractor = AutoModel.from_pretrained(MODEL_PATH)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "print(f\"✓ Feature extractor loaded on {device} (hidden_size={feature_extractor.config.hidden_size})\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. EXTRACT FEATURES FROM TEXT\n",
        "# ============================================================\n",
        "\n",
        "def extract_features_batch(texts, batch_size=32):\n",
        "    \"\"\"\n",
        "    Extract MURIL embeddings for a list of texts\n",
        "    Returns: numpy array of shape (n_samples, 768)\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting features\"):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "            # Tokenize\n",
        "            encoded = tokenizer(\n",
        "                batch_texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Move to device\n",
        "            input_ids = encoded['input_ids'].to(device)\n",
        "            attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "            # Get embeddings\n",
        "            outputs = feature_extractor(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            # Use [CLS] token embedding (first token)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_features.append(cls_embeddings)\n",
        "\n",
        "    return np.vstack(all_features)\n",
        "\n",
        "# Extract features for train and test sets\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXTRACTING FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_texts = train_combined['text'].tolist()\n",
        "train_labels = train_combined[emotion_columns].values.astype(np.float32) # Ensure labels are float32\n",
        "\n",
        "X_train = extract_features_batch(train_texts, BATCH_SIZE_FE)\n",
        "\n",
        "test_texts = test_combined['text'].tolist()\n",
        "test_labels = test_combined[emotion_columns].values.astype(np.float32)   # Ensure labels are float32\n",
        "\n",
        "X_test = extract_features_batch(test_texts, BATCH_SIZE_FE)\n",
        "\n",
        "print(f\"\\n✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. XGBOOST HYPERPARAMETERS - OPTIMIZED FOR MULTI-LABEL\n",
        "# ============================================================\n",
        "\n",
        "\"\"\"\n",
        "XGBoost Hyperparameter Choices:\n",
        "\n",
        "1. max_depth=6: Moderate depth to capture emotion patterns without overfitting\n",
        "2. learning_rate=0.1: Standard rate, balanced convergence\n",
        "3. n_estimators=200: Enough trees for stable predictions\n",
        "4. min_child_weight=3: Regularization to prevent overfitting on small classes\n",
        "5. gamma=0.1: Minimum loss reduction for split (regularization)\n",
        "6. subsample=0.8: Use 80% of data per tree (prevents overfitting)\n",
        "7. colsample_bytree=0.8: Use 80% of features per tree (regularization)\n",
        "8. scale_pos_weight: Automatically computed for each emotion to handle imbalance\n",
        "9. objective='binary:logistic': Binary classification for each label\n",
        "10. eval_metric='logloss': Optimize log loss\n",
        "11. tree_method='hist': Fast histogram-based algorithm\n",
        "12. random_state=42: Reproducibility\n",
        "\"\"\"\n",
        "\n",
        "# Calculate scale_pos_weight for each emotion (handles imbalance)\n",
        "scale_pos_weights = []\n",
        "for i in range(len(emotion_columns)):\n",
        "    neg_count = (train_labels[:, i] == 0).sum()\n",
        "    pos_count = (train_labels[:, i] == 1).sum()\n",
        "    if pos_count > 0:\n",
        "        scale_pos_weights.append(neg_count / pos_count)\n",
        "    else:\n",
        "        scale_pos_weights.append(1.0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING XGBOOST CLASSIFIERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# 4. TRAIN ONE XGBOOST CLASSIFIER PER EMOTION\n",
        "# ============================================================\n",
        "\n",
        "# We'll train separate XGBoost models for each emotion\n",
        "# This gives us more control over per-emotion hyperparameters\n",
        "xgb_models = {}\n",
        "\n",
        "for idx, emotion in enumerate(tqdm(emotion_columns, desc=\"Training XGBoost models\")):\n",
        "\n",
        "    xgb_classifier = XGBClassifier(\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=200,\n",
        "        min_child_weight=3,\n",
        "        gamma=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        scale_pos_weight=scale_pos_weights[idx],  # Handle class imbalance\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='logloss',\n",
        "        tree_method='hist',\n",
        "        random_state=42,\n",
        "        early_stopping_rounds=20,\n",
        "        n_jobs=-1  # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    # Train on this emotion's labels\n",
        "    y_train_emotion = train_labels[:, idx]\n",
        "\n",
        "    # Early stopping with validation set (10% of train)\n",
        "    val_size = int(0.1 * len(X_train))\n",
        "    X_train_split = X_train[:-val_size]\n",
        "    y_train_split = y_train_emotion[:-val_size]\n",
        "    X_val_split = X_train[-val_size:]\n",
        "    y_val_split = y_train_emotion[-val_size:]\n",
        "\n",
        "    # Early stopping with validation set\n",
        "    xgb_classifier.fit(\n",
        "        X_train_split,\n",
        "        y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        verbose=False # Set to True for verbose output\n",
        "    )\n",
        "\n",
        "    xgb_models[emotion] = xgb_classifier\n",
        "\n",
        "print(f\"\\n✓ Trained {len(xgb_models)} XGBoost classifiers\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. MAKE PREDICTIONS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MAKING PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Predict for each emotion\n",
        "y_pred_proba = np.zeros((len(X_test), len(emotion_columns)))\n",
        "y_pred = np.zeros((len(X_test), len(emotion_columns)))\n",
        "\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    y_pred_proba[:, idx] = xgb_models[emotion].predict_proba(X_test)[:, 1]\n",
        "    y_pred[:, idx] = (y_pred_proba[:, idx] > 0.5).astype(int)\n",
        "\n",
        "# ============================================================\n",
        "# 6. EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Overall metrics\n",
        "f1_micro = f1_score(test_labels, y_pred, average='micro', zero_division=0)\n",
        "f1_macro = f1_score(test_labels, y_pred, average='macro', zero_division=0)\n",
        "f1_weighted = f1_score(test_labels, y_pred, average='weighted', zero_division=0)\n",
        "hamming = hamming_loss(test_labels, y_pred)\n",
        "exact_match = accuracy_score(test_labels, y_pred)\n",
        "\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  F1 Micro:     {f1_micro:.4f}\")\n",
        "print(f\"  F1 Macro:     {f1_macro:.4f}\")\n",
        "print(f\"  F1 Weighted:  {f1_weighted:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming:.4f}\")\n",
        "print(f\"  Exact Match:  {exact_match:.4f}\")\n",
        "\n",
        "# Per-emotion performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-EMOTION PERFORMANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "emotion_scores = []\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    f1 = f1_score(test_labels[:, idx], y_pred[:, idx], zero_division=0)\n",
        "    support = test_labels[:, idx].sum()\n",
        "    emotion_scores.append({\n",
        "        'emotion': emotion,\n",
        "        'f1': f1,\n",
        "        'support': int(support)\n",
        "    })\n",
        "    print(f\"{emotion:15s} - F1: {f1:.4f} (support: {int(support)})\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. FEATURE IMPORTANCE ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP 3 EMOTIONS BY FEATURE IMPORTANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Get top emotions by average feature importance\n",
        "for emotion in emotion_columns[:5]:  # Show top 5 for brevity\n",
        "    importance = xgb_models[emotion].feature_importances_\n",
        "    avg_importance = importance.mean()\n",
        "    print(f\"{emotion:15s} - Avg Importance: {avg_importance:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. SAVE MODELS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save XGBoost models\n",
        "with open('./xgboost_emotion_models.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_models, f)\n",
        "\n",
        "# Save feature extractor path for later use\n",
        "with open('./feature_extractor_path.txt', 'w') as f:\n",
        "    f.write(MODEL_PATH)\n",
        "\n",
        "print(\"\\n✓ XGBoost models saved to './xgboost_emotion_models.pkl'\")\n",
        "print(\"✓ Feature extractor path saved\")\n",
        "\n",
        "# ============================================================\n",
        "# 9. INFERENCE FUNCTION FOR MALAYALAM TEXT\n",
        "# ============================================================\n",
        "\n",
        "def predict_emotions_malayalam(text, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predict emotions for Malayalam text using MURIL + XGBoost pipeline\n",
        "\n",
        "    Args:\n",
        "        text: str or list of str (Malayalam text)\n",
        "        threshold: float (probability threshold for positive label)s\n",
        "\n",
        "    Returns:\n",
        "        dict with emotion predictions and probabilities\n",
        "    \"\"\"\n",
        "    # Handle single text or list\n",
        "    if isinstance(text, str):\n",
        "        texts = [text]\n",
        "        single_input = True\n",
        "    else:\n",
        "        texts = text\n",
        "        single_input = False\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_features_batch(texts, batch_size=32)\n",
        "\n",
        "    # Predict with XGBoost\n",
        "    predictions = {}\n",
        "    probabilities = {}\n",
        "\n",
        "    for idx, emotion in enumerate(emotion_columns):\n",
        "        probs = xgb_models[emotion].predict_proba(features)[:, 1]\n",
        "        preds = (probs > threshold).astype(int)\n",
        "\n",
        "        predictions[emotion] = preds\n",
        "        probabilities[emotion] = probs\n",
        "\n",
        "    # Format output\n",
        "    if single_input:\n",
        "        result = {\n",
        "            'emotions': [emotion for emotion in emotion_columns\n",
        "                        if predictions[emotion][0] == 1],\n",
        "            'probabilities': {emotion: float(probabilities[emotion][0])\n",
        "                            for emotion in emotion_columns}\n",
        "        }\n",
        "    else:\n",
        "        result = {\n",
        "            'emotions': [{emotion for emotion in emotion_columns\n",
        "                         if predictions[emotion][i] == 1}\n",
        "                        for i in range(len(texts))],\n",
        "            'probabilities': [{emotion: float(probabilities[emotion][i])\n",
        "                             for emotion in emotion_columns}\n",
        "                            for i in range(len(texts))]\n",
        "        }\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the inference function\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING INFERENCE FUNCTION\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_text = test_texts[0]\n",
        "result = predict_emotions_malayalam(test_text)\n",
        "print(f\"Text: {test_text[:100]}...\")\n",
        "print(f\"Predicted emotions: {result['emotions']}\")\n",
        "print(f\"Top 3 probabilities:\")\n",
        "sorted_probs = sorted(result['probabilities'].items(),\n",
        "                     key=lambda x: x[1], reverse=True)[:3]\n",
        "for emotion, prob in sorted_probs:\n",
        "    print(f\"  {emotion}: {prob:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MURIL + XGBoost Pipeline Complete!\")\n",
        "print(\"Ready for Malayalam emotion inference\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fo66qEJab8y"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU cache cleared.\")\n",
        "else:\n",
        "    print(\"No GPU detected, skipping cache clear.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvRQQ_PqkQH"
      },
      "source": [
        "### IndicBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeiOIJpTzXa_"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjKlAGMNbY1R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# HYPERPARAMETER CHOICES - DETAILED EXPLANATION\n",
        "# ============================================================\n",
        "\"\"\"\n",
        "1. MODEL CHOICE: ai4bharat/indic-bert\n",
        "   - Pre-trained on 12 major Indian languages including Malayalam\n",
        "   - Trained on large-scale Indian language corpora (IndicCorp)\n",
        "   - Better suited for Indian language understanding than multilingual models\n",
        "\n",
        "2. LEARNING RATE: 2e-5 (classification head), 1e-5 (encoder layers)\n",
        "   - Lower LR for encoder to preserve cross-lingual representations\n",
        "   - Higher LR for head since it's trained from scratch\n",
        "\n",
        "3. BATCH SIZE: 16 (with gradient accumulation steps = 2, effective = 32)\n",
        "   - Balanced for GPU memory and stable gradients\n",
        "   - Effective batch size 32 is optimal for transformer fine-tuning\n",
        "\n",
        "4. EPOCHS: 5-8\n",
        "   - Start with 5, use early stopping to prevent overfitting\n",
        "   - Cross-lingual transfer needs careful regularization\n",
        "\n",
        "5. WARMUP: 10% of training steps\n",
        "   - Gradual learning rate increase prevents destabilizing pre-trained weights\n",
        "\n",
        "6. WEIGHT DECAY: 0.01\n",
        "   - Regularization to maintain generalization to Malayalam\n",
        "\n",
        "7. DROPOUT: 0.3 (classification head)\n",
        "   - Higher dropout for regularization during cross-lingual transfer\n",
        "\n",
        "8. GRADIENT CLIPPING: 1.0\n",
        "   - Prevents exploding gradients with multi-label BCE loss\n",
        "\n",
        "9. FREEZING STRATEGY: Gradual unfreezing\n",
        "   - Phase 1: Freeze encoder, train classification head (3 epochs)\n",
        "   - Phase 2: Unfreeze top 4 encoder layers (3 epochs)\n",
        "   - Preserves cross-lingual knowledge while adapting to emotions\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "IndicBERT Fine-tuning for Multi-Label Emotion Classification\n",
        "Optimized for Indian languages with proper BCE loss and model architecture\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 1. SETUP AND CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "MODEL_NAME = \"ai4bharat/indic-bert\"\n",
        "NUM_LABELS = 28\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ============================================================\n",
        "# 2. PREPARE DATASETS WITH PROPER FORMATTING\n",
        "# ============================================================\n",
        "\n",
        "class EmotionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(label)  # Float for BCE loss\n",
        "        }\n",
        "\n",
        "# Prepare data\n",
        "train_texts = train_combined['text'].tolist()\n",
        "train_labels = train_combined[emotion_columns].values.astype(np.float32)\n",
        "\n",
        "test_texts = test_combined['text'].tolist()\n",
        "test_labels = test_combined[emotion_columns].values.astype(np.float32)\n",
        "\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Calculate positive weights for class imbalance\n",
        "num_positives = train_labels.sum(axis=0)\n",
        "num_samples = len(train_dataset)\n",
        "num_negatives = num_samples - num_positives\n",
        "# Calculate ratio: negatives / positives\n",
        "pos_weights = torch.tensor(num_negatives / num_positives, dtype=torch.float32)\n",
        "pos_weights = pos_weights.to(device)  # Move to GPU\n",
        "print(f\"Calculated pos_weights (first 5): {pos_weights[:5].cpu().numpy()}\")\n",
        "\n",
        "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Check label distribution\n",
        "print(\"\\nLabel distribution in training set:\")\n",
        "for idx, emotion in enumerate(emotion_columns[:5]):  # Show first 5\n",
        "    pos_count = (train_labels[:, idx] == 1).sum()\n",
        "    print(f\"  {emotion}: {pos_count}/{len(train_labels)} ({pos_count/len(train_labels)*100:.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. MODEL ARCHITECTURE FOR INDICBERT\n",
        "# ============================================================\n",
        "\n",
        "class IndicBERTForMultiLabelClassification(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, pos_weights=None, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.pos_weights = pos_weights\n",
        "\n",
        "        # Load IndicBERT base model\n",
        "        self.indicbert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Classification head with dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.indicbert.config.hidden_size, num_labels)\n",
        "\n",
        "        # Initialize classifier weights properly\n",
        "        nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.zeros_(self.classifier.bias)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Get IndicBERT outputs\n",
        "        outputs = self.indicbert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Use [CLS] token representation (first token)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Binary Cross Entropy with Logits Loss with positive weights\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "# Initialize model\n",
        "model = IndicBERTForMultiLabelClassification(\n",
        "    MODEL_NAME,\n",
        "    NUM_LABELS,\n",
        "    pos_weights=pos_weights,\n",
        "    dropout=0.3\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"\\nModel initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. DIAGNOSTIC: Check Initial Predictions\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIAGNOSTIC: Initial Model Predictions (Before Training)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(torch.utils.data.DataLoader(train_dataset, batch_size=8)))\n",
        "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
        "    sample_attention_mask = sample_batch['attention_mask'].to(device)\n",
        "\n",
        "    outputs = model(sample_input_ids, sample_attention_mask)\n",
        "    sample_logits = outputs['logits']\n",
        "    sample_probs = torch.sigmoid(sample_logits)\n",
        "\n",
        "    print(f\"Logits range: [{sample_logits.min():.3f}, {sample_logits.max():.3f}]\")\n",
        "    print(f\"Probabilities range: [{sample_probs.min():.3f}, {sample_probs.max():.3f}]\")\n",
        "    print(f\"Mean probability: {sample_probs.mean():.3f}\")\n",
        "    print(f\"Predictions > 0.5: {(sample_probs > 0.5).sum().item()} out of {sample_probs.numel()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. FREEZING STRATEGY\n",
        "# ============================================================\n",
        "\n",
        "def freeze_encoder(model):\n",
        "    \"\"\"Freeze IndicBERT encoder, keep classification head trainable\"\"\"\n",
        "    for param in model.indicbert.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Ensure classifier is trainable\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "    print(\"✓ Encoder frozen - only classification head will be trained\")\n",
        "\n",
        "def unfreeze_top_layers(model, num_layers=4):\n",
        "    \"\"\"Unfreeze top N encoder layers in an ALBERT-like model.\"\"\"\n",
        "    # Collect all individual AlbertLayer instances\n",
        "    all_albert_layers = []\n",
        "    for group in model.indicbert.encoder.albert_layer_groups:\n",
        "        for albert_layer in group.albert_layers:\n",
        "            all_albert_layers.append(albert_layer)\n",
        "\n",
        "    total_layers = len(all_albert_layers)\n",
        "\n",
        "    if num_layers > total_layers:\n",
        "        print(f\"Warning: Requested to unfreeze {num_layers} layers, but model only has {total_layers} layers. Unfreezing all layers.\")\n",
        "        layers_to_unfreeze = all_albert_layers\n",
        "    else:\n",
        "        layers_to_unfreeze = all_albert_layers[total_layers - num_layers:]\n",
        "\n",
        "    for layer in layers_to_unfreeze:\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = True\n",
        "    print(f\"✓ Top {len(layers_to_unfreeze)} encoder layers unfrozen\")\n",
        "\n",
        "freeze_encoder(model)\n",
        "\n",
        "# ============================================================\n",
        "# 6. IMPROVED METRICS WITH DEBUGGING\n",
        "# ============================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probs = 1 / (1 + np.exp(-logits))  # Sigmoid\n",
        "    predictions = (probs > 0.5).astype(int)\n",
        "\n",
        "    # Debug: Check prediction distribution\n",
        "    num_positives = predictions.sum()\n",
        "    total_predictions = predictions.size\n",
        "\n",
        "    # Multi-label metrics\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "    exact_match = accuracy_score(labels, predictions)\n",
        "\n",
        "    # Additional diagnostic metrics\n",
        "    avg_labels_per_sample = labels.sum(axis=1).mean()\n",
        "    avg_predictions_per_sample = predictions.sum(axis=1).mean()\n",
        "\n",
        "    return {\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'hamming_loss': hamming,\n",
        "        'exact_match': exact_match,\n",
        "        'num_positive_preds': num_positives,\n",
        "        'avg_labels_per_sample': avg_labels_per_sample,\n",
        "        'avg_preds_per_sample': avg_predictions_per_sample\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# 7. PHASE 1 TRAINING - CLASSIFICATION HEAD ONLY\n",
        "# ============================================================\n",
        "\n",
        "training_args_phase1 = TrainingArguments(\n",
        "    output_dir='./indicbert_emotion_phase1',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=5e-5,  # Higher LR for classification head\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.15,\n",
        "    logging_dir='./logs_phase1',\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1_macro',\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_num_workers=2,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    label_smoothing_factor=0.0  # No label smoothing for multi-label\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1: Training Classification Head (Encoder Frozen)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "trainer_phase1 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_phase1,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")\n",
        "\n",
        "trainer_phase1.train()\n",
        "\n",
        "# Evaluate Phase 1\n",
        "phase1_results = trainer_phase1.evaluate()\n",
        "print(\"\\nPhase 1 Results:\")\n",
        "for key, value in phase1_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. POST-PHASE 1 DIAGNOSTIC\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POST-PHASE 1 DIAGNOSTIC\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_batch = next(iter(torch.utils.data.DataLoader(test_dataset, batch_size=8)))\n",
        "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
        "    sample_attention_mask = sample_batch['attention_mask'].to(device)\n",
        "    sample_labels = sample_batch['labels']\n",
        "\n",
        "    outputs = model(sample_input_ids, sample_attention_mask)\n",
        "    sample_logits = outputs['logits']\n",
        "    sample_probs = torch.sigmoid(sample_logits)\n",
        "\n",
        "    print(f\"Logits range: [{sample_logits.min():.3f}, {sample_logits.max():.3f}]\")\n",
        "    print(f\"Probabilities range: [{sample_probs.min():.3f}, {sample_probs.max():.3f}]\")\n",
        "    print(f\"Mean probability: {sample_probs.mean():.3f}\")\n",
        "    print(f\"Predictions > 0.5: {(sample_probs > 0.5).sum().item()} out of {sample_probs.numel()}\")\n",
        "    print(f\"Actual positive labels: {sample_labels.sum().item()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 9. PHASE 2 - UNFREEZE TOP LAYERS\n",
        "# ============================================================\n",
        "\n",
        "# Only continue to Phase 2 if model is learning\n",
        "if phase1_results['eval_f1_macro'] > 0.01:\n",
        "    print(\"\\n✓ Model is learning! Proceeding to Phase 2...\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 2: Fine-tuning Top Encoder Layers\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    unfreeze_top_layers(model, num_layers=4)\n",
        "\n",
        "    training_args_phase2 = TrainingArguments(\n",
        "        output_dir='./indicbert_emotion_phase2',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=32,\n",
        "        gradient_accumulation_steps=2,\n",
        "        learning_rate=2e-5,  # Lower LR for fine-tuning\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.15,\n",
        "        max_grad_norm=1.0,\n",
        "        logging_dir='./logs_phase2',\n",
        "        logging_steps=50,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=200,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1_macro',\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=2,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    trainer_phase2 = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_phase2,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    )\n",
        "\n",
        "    trainer_phase2.train()\n",
        "    final_results = trainer_phase2.evaluate()\n",
        "\n",
        "else:\n",
        "    print(\"\\n⚠ WARNING: Model not learning in Phase 1!\")\n",
        "    print(\"Skipping Phase 2. Need to debug further.\")\n",
        "    final_results = phase1_results\n",
        "\n",
        "# ============================================================\n",
        "# 10. FINAL EVALUATION WITH ADAPTIVE THRESHOLD\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL EVALUATION WITH ADAPTIVE THRESHOLD\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Collect all predictions\n",
        "model.eval()\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in torch.utils.data.DataLoader(test_dataset, batch_size=32):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        all_logits.append(outputs['logits'].cpu())\n",
        "        all_labels.append(batch['labels'])\n",
        "\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "all_probs = torch.sigmoid(all_logits).numpy()\n",
        "all_labels = all_labels.numpy()\n",
        "\n",
        "# Test different thresholds\n",
        "print(\"Testing different prediction thresholds:\")\n",
        "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    preds = (all_probs > threshold).astype(int)\n",
        "    f1_macro = f1_score(all_labels, preds, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(all_labels, preds, average='micro', zero_division=0)\n",
        "    avg_preds = preds.sum() / len(preds)\n",
        "    print(f\"  Threshold {threshold:.1f} - F1 Macro: {f1_macro:.4f}, F1 Micro: {f1_micro:.4f}, Avg preds/sample: {avg_preds:.2f}\")\n",
        "\n",
        "# Use best threshold\n",
        "best_threshold = 0.5\n",
        "pred_labels = (all_probs > best_threshold).astype(int)\n",
        "\n",
        "print(f\"\\nUsing threshold: {best_threshold}\")\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"  F1 Macro:     {f1_score(all_labels, pred_labels, average='macro', zero_division=0):.4f}\")\n",
        "print(f\"  F1 Micro:     {f1_score(all_labels, pred_labels, average='micro', zero_division=0):.4f}\")\n",
        "print(f\"  F1 Weighted:  {f1_score(all_labels, pred_labels, average='weighted', zero_division=0):.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_loss(all_labels, pred_labels):.4f}\")\n",
        "print(f\"  Exact Match:  {accuracy_score(all_labels, pred_labels):.4f}\")\n",
        "\n",
        "# Per-emotion performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-EMOTION PERFORMANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    f1 = f1_score(all_labels[:, idx], pred_labels[:, idx], zero_division=0)\n",
        "    support = all_labels[:, idx].sum()\n",
        "    avg_prob = all_probs[:, idx].mean()\n",
        "    print(f\"{emotion:15s} - F1: {f1:.4f}, Support: {int(support):4d}, Avg Prob: {avg_prob:.3f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 11. SAVE MODEL\n",
        "# ============================================================\n",
        "\n",
        "# Save the IndicBERT feature extractor\n",
        "model.indicbert.save_pretrained('./indicbert_emotion_final')\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained('./indicbert_emotion_final')\n",
        "\n",
        "# Save the classification head state_dict\n",
        "torch.save(model.classifier.state_dict(), './indicbert_emotion_final/classifier_head.pt')\n",
        "\n",
        "print(\"\\n✓ IndicBERT feature extractor and tokenizer saved to './indicbert_emotion_final'\")\n",
        "print(\"✓ Classification head state_dict saved to './indicbert_emotion_final/classifier_head.pt'\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnmr2Gzj1w7J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from xgboost import XGBClassifier # Removed 'callback' as it's not needed with direct args\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, hamming_loss, classification_report\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG / PATHS\n",
        "# -------------------------------------------------------------------\n",
        "MODEL_PATH = './indicbert_emotion_final'  # folder you saved: contains tokenizer + base model\n",
        "CLASSIFIER_HEAD_PATH = os.path.join(MODEL_PATH, 'classifier_head.pt')  # optional\n",
        "EMBED_MAX_LENGTH = 128\n",
        "BATCH_SIZE_FE = 32\n",
        "MODEL_NAME = \"ai4bharat/indic-bert\"\n",
        "\n",
        "# Ensure these variables are available in this scope:\n",
        "# - train_combined, test_combined, emotion_columns\n",
        "# (They were defined in your training script. If not, load them here.)\n",
        "\n",
        "NUM_LABELS = len(emotion_columns)\n",
        "\n",
        "# ============================================================\n",
        "# 1. LOAD SAVED TOKENIZER + FEATURE EXTRACTOR (MURIL)\n",
        "# ============================================================\n",
        "print(\"Loading tokenizer from original model name and inidcBERT feature extractor from:\", MODEL_PATH)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) # Load tokenizer from original name\n",
        "\n",
        "# Load encoder-only (AutoModel) from the saved folder\n",
        "feature_extractor = AutoModel.from_pretrained(MODEL_PATH)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "print(f\"✓ Feature extractor loaded on {device} (hidden_size={feature_extractor.config.hidden_size})\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. EXTRACT FEATURES FROM TEXT\n",
        "# ============================================================\n",
        "\n",
        "def extract_features_batch(texts, batch_size=32):\n",
        "    \"\"\"\n",
        "    Extract MURIL embeddings for a list of texts\n",
        "    Returns: numpy array of shape (n_samples, 768)\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting features\"):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "            # Tokenize\n",
        "            encoded = tokenizer(\n",
        "                batch_texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Move to device\n",
        "            input_ids = encoded['input_ids'].to(device)\n",
        "            attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "            # Get embeddings\n",
        "            outputs = feature_extractor(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            # Use [CLS] token embedding (first token)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_features.append(cls_embeddings)\n",
        "\n",
        "    return np.vstack(all_features)\n",
        "\n",
        "# Extract features for train and test sets\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXTRACTING FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_texts = train_combined['text'].tolist()\n",
        "train_labels = train_combined[emotion_columns].values.astype(np.float32) # Ensure labels are float32\n",
        "\n",
        "X_train = extract_features_batch(train_texts, BATCH_SIZE_FE)\n",
        "\n",
        "test_texts = test_combined['text'].tolist()\n",
        "test_labels = test_combined[emotion_columns].values.astype(np.float32)   # Ensure labels are float32\n",
        "\n",
        "X_test = extract_features_batch(test_texts, BATCH_SIZE_FE)\n",
        "\n",
        "print(f\"\\n✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. XGBOOST HYPERPARAMETERS - OPTIMIZED FOR MULTI-LABEL\n",
        "# ============================================================\n",
        "\n",
        "\"\"\"\n",
        "XGBoost Hyperparameter Choices:\n",
        "\n",
        "1. max_depth=6: Moderate depth to capture emotion patterns without overfitting\n",
        "2. learning_rate=0.1: Standard rate, balanced convergence\n",
        "3. n_estimators=200: Enough trees for stable predictions\n",
        "4. min_child_weight=3: Regularization to prevent overfitting on small classes\n",
        "5. gamma=0.1: Minimum loss reduction for split (regularization)\n",
        "6. subsample=0.8: Use 80% of data per tree (prevents overfitting)\n",
        "7. colsample_bytree=0.8: Use 80% of features per tree (regularization)\n",
        "8. scale_pos_weight: Automatically computed for each emotion to handle imbalance\n",
        "9. objective='binary:logistic': Binary classification for each label\n",
        "10. eval_metric='logloss': Optimize log loss\n",
        "11. tree_method='hist': Fast histogram-based algorithm\n",
        "12. random_state=42: Reproducibility\n",
        "\"\"\"\n",
        "\n",
        "# Calculate scale_pos_weight for each emotion (handles imbalance)\n",
        "scale_pos_weights = []\n",
        "for i in range(len(emotion_columns)):\n",
        "    neg_count = (train_labels[:, i] == 0).sum()\n",
        "    pos_count = (train_labels[:, i] == 1).sum()\n",
        "    if pos_count > 0:\n",
        "        scale_pos_weights.append(neg_count / pos_count)\n",
        "    else:\n",
        "        scale_pos_weights.append(1.0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING XGBOOST CLASSIFIERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# 4. TRAIN ONE XGBOOST CLASSIFIER PER EMOTION\n",
        "# ============================================================\n",
        "\n",
        "# We'll train separate XGBoost models for each emotion\n",
        "# This gives us more control over per-emotion hyperparameters\n",
        "xgb_models = {}\n",
        "\n",
        "for idx, emotion in enumerate(tqdm(emotion_columns, desc=\"Training XGBoost models\")):\n",
        "\n",
        "    xgb_classifier = XGBClassifier(\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=200,\n",
        "        min_child_weight=3,\n",
        "        gamma=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        scale_pos_weight=scale_pos_weights[idx],  # Handle class imbalance\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='logloss',\n",
        "        tree_method='hist',\n",
        "        random_state=42,\n",
        "        early_stopping_rounds=20,\n",
        "        n_jobs=-1  # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    # Train on this emotion's labels\n",
        "    y_train_emotion = train_labels[:, idx]\n",
        "\n",
        "    # Early stopping with validation set (10% of train)\n",
        "    val_size = int(0.1 * len(X_train))\n",
        "    X_train_split = X_train[:-val_size]\n",
        "    y_train_split = y_train_emotion[:-val_size]\n",
        "    X_val_split = X_train[-val_size:]\n",
        "    y_val_split = y_train_emotion[-val_size:]\n",
        "\n",
        "    # Early stopping with validation set\n",
        "    xgb_classifier.fit(\n",
        "        X_train_split,\n",
        "        y_train_split,\n",
        "        eval_set=[(X_val_split, y_val_split)],\n",
        "        verbose=False # Set to True for verbose output\n",
        "    )\n",
        "\n",
        "    xgb_models[emotion] = xgb_classifier\n",
        "\n",
        "print(f\"\\n✓ Trained {len(xgb_models)} XGBoost classifiers\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. MAKE PREDICTIONS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MAKING PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Predict for each emotion\n",
        "y_pred_proba = np.zeros((len(X_test), len(emotion_columns)))\n",
        "y_pred = np.zeros((len(X_test), len(emotion_columns)))\n",
        "\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    y_pred_proba[:, idx] = xgb_models[emotion].predict_proba(X_test)[:, 1]\n",
        "    y_pred[:, idx] = (y_pred_proba[:, idx] > 0.5).astype(int)\n",
        "\n",
        "# ============================================================\n",
        "# 6. EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Overall metrics\n",
        "f1_micro = f1_score(test_labels, y_pred, average='micro', zero_division=0)\n",
        "f1_macro = f1_score(test_labels, y_pred, average='macro', zero_division=0)\n",
        "f1_weighted = f1_score(test_labels, y_pred, average='weighted', zero_division=0)\n",
        "hamming = hamming_loss(test_labels, y_pred)\n",
        "exact_match = accuracy_score(test_labels, y_pred)\n",
        "\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  F1 Micro:     {f1_micro:.4f}\")\n",
        "print(f\"  F1 Macro:     {f1_macro:.4f}\")\n",
        "print(f\"  F1 Weighted:  {f1_weighted:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming:.4f}\")\n",
        "print(f\"  Exact Match:  {exact_match:.4f}\")\n",
        "\n",
        "# Per-emotion performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PER-EMOTION PERFORMANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "emotion_scores = []\n",
        "for idx, emotion in enumerate(emotion_columns):\n",
        "    f1 = f1_score(test_labels[:, idx], y_pred[:, idx], zero_division=0)\n",
        "    support = test_labels[:, idx].sum()\n",
        "    emotion_scores.append({\n",
        "        'emotion': emotion,\n",
        "        'f1': f1,\n",
        "        'support': int(support)\n",
        "    })\n",
        "    print(f\"{emotion:15s} - F1: {f1:.4f} (support: {int(support)})\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. FEATURE IMPORTANCE ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP 3 EMOTIONS BY FEATURE IMPORTANCE\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Get top emotions by average feature importance\n",
        "for emotion in emotion_columns[:5]:  # Show top 5 for brevity\n",
        "    importance = xgb_models[emotion].feature_importances_\n",
        "    avg_importance = importance.mean()\n",
        "    print(f\"{emotion:15s} - Avg Importance: {avg_importance:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. SAVE MODELS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save XGBoost models\n",
        "with open('./xgboost_emotion_models.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_models, f)\n",
        "\n",
        "# Save feature extractor path for later use\n",
        "with open('./feature_extractor_path.txt', 'w') as f:\n",
        "    f.write(MODEL_PATH)\n",
        "\n",
        "print(\"\\n✓ XGBoost models saved to './xgboost_emotion_models.pkl'\")\n",
        "print(\"✓ Feature extractor path saved\")\n",
        "\n",
        "# ============================================================\n",
        "# 9. INFERENCE FUNCTION FOR MALAYALAM TEXT\n",
        "# ============================================================\n",
        "\n",
        "def predict_emotions_malayalam(text, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predict emotions for Malayalam text using MURIL + XGBoost pipeline\n",
        "\n",
        "    Args:\n",
        "        text: str or list of str (Malayalam text)\n",
        "        threshold: float (probability threshold for positive label)s\n",
        "\n",
        "    Returns:\n",
        "        dict with emotion predictions and probabilities\n",
        "    \"\"\"\n",
        "    # Handle single text or list\n",
        "    if isinstance(text, str):\n",
        "        texts = [text]\n",
        "        single_input = True\n",
        "    else:\n",
        "        texts = text\n",
        "        single_input = False\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_features_batch(texts, batch_size=32)\n",
        "\n",
        "    # Predict with XGBoost\n",
        "    predictions = {}\n",
        "    probabilities = {}\n",
        "\n",
        "    for idx, emotion in enumerate(emotion_columns):\n",
        "        probs = xgb_models[emotion].predict_proba(features)[:, 1]\n",
        "        preds = (probs > threshold).astype(int)\n",
        "\n",
        "        predictions[emotion] = preds\n",
        "        probabilities[emotion] = probs\n",
        "\n",
        "    # Format output\n",
        "    if single_input:\n",
        "        result = {\n",
        "            'emotions': [emotion for emotion in emotion_columns\n",
        "                        if predictions[emotion][0] == 1],\n",
        "            'probabilities': {emotion: float(probabilities[emotion][0])\n",
        "                            for emotion in emotion_columns}\n",
        "        }\n",
        "    else:\n",
        "        result = {\n",
        "            'emotions': [{emotion for emotion in emotion_columns\n",
        "                         if predictions[emotion][i] == 1}\n",
        "                        for i in range(len(texts))],\n",
        "            'probabilities': [{emotion: float(probabilities[emotion][i])\n",
        "                             for emotion in emotion_columns}\n",
        "                            for i in range(len(texts))]\n",
        "        }\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the inference function\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING INFERENCE FUNCTION\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_text = test_texts[0]\n",
        "result = predict_emotions_malayalam(test_text)\n",
        "print(f\"Text: {test_text[:100]}...\")\n",
        "print(f\"Predicted emotions: {result['emotions']}\")\n",
        "print(f\"Top 3 probabilities:\")\n",
        "sorted_probs = sorted(result['probabilities'].items(),\n",
        "                     key=lambda x: x[1], reverse=True)[:3]\n",
        "for emotion, prob in sorted_probs:\n",
        "    print(f\"  {emotion}: {prob:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MURIL + XGBoost Pipeline Complete!\")\n",
        "print(\"Ready for Malayalam emotion inference\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OQrXgi6-HtF"
      },
      "source": [
        "# Flagging Suicidal Language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDadTqZU-NC0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    cohen_kappa_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error\n",
        ")\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import warnings\n",
        "from collections import Counter\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QscepeNaAKwS"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN-__6Ao7TlL"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# UNDERSTANDING C-SSRS ORDINAL LABELS\n",
        "# ============================================================\n",
        "\"\"\"\n",
        "C-SSRS (Columbia Suicide Severity Rating Scale) - ORDINAL CLASSIFICATION\n",
        "\n",
        "Dataset Distribution:\n",
        "- Ideation:    171 (34.2%) - Level 2\n",
        "- Supportive:  108 (21.6%) - Level 0 (lowest severity)\n",
        "- Indicator:    99 (19.8%) - Level 1\n",
        "- Behavior:     77 (15.4%) - Level 3\n",
        "- Attempt:      45 ( 9.0%) - Level 4 (highest severity)\n",
        "\n",
        "Total: 500 samples (highly imbalanced, especially Attempt class)\n",
        "\n",
        "ORDINAL SEVERITY SCALE:\n",
        "0. Supportive   - No risk, providing support to others\n",
        "1. Indicator    - Risk indicators present but no active ideation\n",
        "2. Ideation     - Suicidal thoughts present (most common)\n",
        "3. Behavior     - Preparatory behaviors for suicide\n",
        "4. Attempt      - Actual suicide attempt (least common)\n",
        "\n",
        "KEY INSIGHTS FOR ORDINAL MODELING:\n",
        "- Predicting \"Attempt\" as \"Behavior\" is better than predicting as \"Supportive\"\n",
        "- We'll use ordinal loss that penalizes distance from true label\n",
        "- Class weights to handle severe imbalance (Attempt only 9%)\n",
        "- Use Mean Absolute Error (MAE) as a key metric for ordinal distance\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 1. DATA LOADING AND EXPLORATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"LOADING C-SSRS SUICIDALITY DATASET - ORDINAL CLASSIFICATION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('/content/PHQ9-Malayalam/CSSRS.csv')\n",
        "    print(\"✓ Loaded csv\")\n",
        "except:\n",
        "\n",
        "    print(\"⚠ Dataset not found. Please ensure the CSV file is in the directory.\")\n",
        "    raise FileNotFoundError(\"Dataset file not found\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs5WDMF_AVWq"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2. DATA CLEANING AND PREPROCESSING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA CLEANING AND PREPROCESSING\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Identify text and label columns\n",
        "text_col = None\n",
        "label_col = None\n",
        "\n",
        "for col in df.columns:\n",
        "    col_lower = col.lower()\n",
        "    if 'text' in col_lower or 'post' in col_lower or 'content' in col_lower:\n",
        "        text_col = col\n",
        "    if 'label' in col_lower or 'class' in col_lower:\n",
        "        label_col = col\n",
        "\n",
        "if text_col is None:\n",
        "    text_col = df.columns[0]\n",
        "if label_col is None:\n",
        "    label_col = df.columns[1] if len(df.columns) > 1 else df.columns[-1]\n",
        "\n",
        "print(f\"Using text column: '{text_col}'\")\n",
        "print(f\"Using label column: '{label_col}'\")\n",
        "\n",
        "# Rename for consistency\n",
        "df = df.rename(columns={text_col: 'text', label_col: 'label'})\n",
        "\n",
        "# Remove rows with missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df[['text', 'label']].isnull().sum())\n",
        "\n",
        "df = df.dropna(subset=['text', 'label'])\n",
        "print(f\"✓ Removed missing values. Shape: {df.shape}\")\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean Reddit post text while preserving emotion indicators\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove URLs but keep text structure\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '[URL]', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove Reddit-specific formatting\n",
        "    text = re.sub(r'\\[deleted\\]|\\[removed\\]', '', text)\n",
        "\n",
        "    # Remove excessive special characters but keep punctuation\n",
        "    text = re.sub(r'[^\\w\\s.,!?;:\\'\\\"-]', ' ', text)\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Filter very short posts\n",
        "    if len(text) < 10:\n",
        "        return \"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "df = df[df['text'] != \"\"]\n",
        "print(f\"✓ Text cleaned. Shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgnDLAwUAZYJ"
      },
      "outputs": [],
      "source": [
        "def standardize_label(label):\n",
        "    \"\"\"Convert to standard label format\"\"\"\n",
        "    if isinstance(label, str):\n",
        "        label = label.strip().lower()\n",
        "        label = label.replace(' ', '').replace('_', '')\n",
        "\n",
        "        if label in ['a', 'supportive', 'support', 'notrisk']:\n",
        "            return 'Supportive'\n",
        "        elif label in ['b', 'indicator', 'ind', 'risk']:\n",
        "            return 'Indicator'\n",
        "        elif label in ['c', 'ideation', 'idea', 'thoughts']:\n",
        "            return 'Ideation'\n",
        "        elif label in ['d', 'behavior', 'behav', 'preparation']:\n",
        "            return 'Behavior'\n",
        "        elif label in ['e', 'attempt', 'att', 'try']:\n",
        "            return 'Attempt'\n",
        "    return str(label).strip().title()\n",
        "\n",
        "df['label'] = df['label'].apply(standardize_label)\n",
        "\n",
        "# Verify we have the expected distribution\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LABEL DISTRIBUTION (Should match: Ideation 171, Supportive 108, etc.)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "label_counts = df['label'].value_counts()\n",
        "print(label_counts)\n",
        "print(f\"\\nTotal samples: {len(df)}\")\n",
        "print(\"\\nPercentage distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"  {label:12s}: {count:3d} ({count/len(df)*100:5.1f}%)\")\n",
        "\n",
        "# ORDINAL label mapping (Supportive=0 to Attempt=4)\n",
        "label_to_id = {\n",
        "    'Supportive': 0,\n",
        "    'Indicator': 1,\n",
        "    'Ideation': 2,\n",
        "    'Behavior': 3,\n",
        "    'Attempt': 4\n",
        "}\n",
        "id_to_label = {v: k for k, v in label_to_id.items()}\n",
        "\n",
        "df['label_id'] = df['label'].map(label_to_id)\n",
        "\n",
        "# Remove any unmapped labels\n",
        "df = df.dropna(subset=['label_id'])\n",
        "df['label_id'] = df['label_id'].astype(int)\n",
        "print(f\"\\n✓ Labels standardized. Final shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1OzwIatAcp1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 3. CLASS IMBALANCE ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASS IMBALANCE ANALYSIS (Critical for Attempt class with only 45 samples)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "class_counts = df['label_id'].value_counts().sort_index()\n",
        "for label_id in sorted(label_to_id.values()):\n",
        "    label_name = id_to_label[label_id]\n",
        "    count = class_counts.get(label_id, 0)\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"Level {label_id} - {label_name:12s}: {count:3d} samples ({percentage:5.1f}%)\")\n",
        "\n",
        "# Calculate class weights - more aggressive for rare classes\n",
        "total_samples = len(df)\n",
        "class_weights = []\n",
        "for label_id in sorted(label_to_id.values()):\n",
        "    count = class_counts.get(label_id, 1)\n",
        "    weight = total_samples / (len(label_to_id) * count)\n",
        "    # NO smoothing - use raw weights to force minority learning\n",
        "    weight = weight * 2.0  # Double the weights\n",
        "    class_weights.append(weight)\n",
        "\n",
        "class_weights = torch.FloatTensor(class_weights)\n",
        "print(f\"\\nClass weights (sqrt-smoothed, amplified for rare classes):\")\n",
        "for label_id, weight in enumerate(class_weights):\n",
        "    print(f\"  {id_to_label[label_id]:12s}: {weight:.3f}\")\n",
        "\n",
        "# Text statistics\n",
        "df['text_length'] = df['text'].str.len()\n",
        "df['word_count'] = df['text'].str.split().str.len()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT STATISTICS BY SEVERITY LEVEL\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for label_id in sorted(label_to_id.values()):\n",
        "    label_name = id_to_label[label_id]\n",
        "    subset = df[df['label_id'] == label_id]\n",
        "    avg_len = subset['text_length'].mean()\n",
        "    avg_words = subset['word_count'].mean()\n",
        "    print(f\"{label_name:12s}: Avg length={avg_len:6.1f} chars, Avg words={avg_words:5.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH737d-XAkLz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hh-OIaWAi76"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def augment_minority_classes(train_df, label_col='label_id', target_samples=150):\n",
        "    \"\"\"Oversample minority classes to balance dataset\"\"\"\n",
        "    from sklearn.utils import resample\n",
        "\n",
        "    frames = []\n",
        "    for label_id in sorted(train_df[label_col].unique()):\n",
        "        subset = train_df[train_df[label_col] == label_id]\n",
        "\n",
        "        if len(subset) < target_samples:\n",
        "            # Oversample minority class\n",
        "            subset_upsampled = resample(\n",
        "                subset,\n",
        "                replace=True,\n",
        "                n_samples=target_samples,\n",
        "                random_state=42\n",
        "            )\n",
        "            frames.append(subset_upsampled)\n",
        "        else:\n",
        "            frames.append(subset)\n",
        "\n",
        "    return pd.concat(frames, ignore_index=True)\n",
        "\n",
        "# ============================================================\n",
        "# 4. STRATIFIED K-FOLD FOR ROBUST EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING STRATIFIED TRAIN-VALIDATION-TEST SPLIT\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# First, separate test set (20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label_id']\n",
        ")\n",
        "\n",
        "# Then split train into train and validation (80-20 of remaining)\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_val_df['label_id']\n",
        ")\n",
        "\n",
        "# Oversample minority classes in training set\n",
        "print(\"\\nBalancing training set with oversampling...\")\n",
        "print(f\"Before: {len(train_df)} samples\")\n",
        "train_df = augment_minority_classes(train_df, label_col='label_id', target_samples=120)\n",
        "print(f\"After: {len(train_df)} samples\")\n",
        "print(\"New distribution:\")\n",
        "print(train_df['label'].value_counts())\n",
        "\n",
        "print(f\"Training samples:   {len(train_df):3d} ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"Validation samples: {len(val_df):3d} ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test samples:       {len(test_df):3d} ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nTraining set distribution:\")\n",
        "print(train_df['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nValidation set distribution:\")\n",
        "print(val_df['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nTest set distribution:\")\n",
        "print(test_df['label'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFlhC_21Cyhp"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU cache cleared.\")\n",
        "else:\n",
        "    print(\"No GPU detected, skipping cache clear.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsK52v-WAqjD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# 5. DATASET CLASS WITH ORDINAL AWARENESS\n",
        "# ============================================================\n",
        "\n",
        "class CSSRSDataset(Dataset):\n",
        "    \"\"\"Dataset with optional augmentation for minority classes\"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyKATLgu842V"
      },
      "outputs": [],
      "source": [
        "class OrdinalCSSRSClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Ordinal classification model using MURIL for cross-lingual transfer.\n",
        "    Uses ordinal loss to penalize distance from true severity level.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, num_classes=5, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "        # LESS AGGRESSIVE FREEZING - only freeze embeddings\n",
        "        for param in self.encoder.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Improved classification head with batch norm\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        pooled_output = self.batch_norm(pooled_output)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEGLPWGW9hC5"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss to handle severe class imbalance.\n",
        "    Better than simple class weighting for rare classes.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # class weights\n",
        "        self.gamma = gamma  # focusing parameter\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        ce_loss = nn.functional.cross_entropy(logits, labels, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha[labels]\n",
        "            focal_loss = alpha_t * focal_loss\n",
        "\n",
        "        return focal_loss.mean()\n",
        "\n",
        "\n",
        "class OrdinalCrossEntropyLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Weighted ordinal cross-entropy loss.\n",
        "    Penalizes predictions based on distance from true label.\n",
        "    \"\"\"\n",
        "    def __init__(self, class_weights=None, ordinal_weight=0.3):\n",
        "        super().__init__()\n",
        "        self.class_weights = class_weights\n",
        "        self.ordinal_weight = ordinal_weight\n",
        "        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Standard cross-entropy loss with class weights\n",
        "        ce = self.ce_loss(logits, labels)\n",
        "\n",
        "        # Ordinal penalty: penalize distance from true label\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        ordinal_penalty = torch.abs(preds - labels).float().mean()\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = ce + self.ordinal_weight * ordinal_penalty\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class ImprovedOrdinalLoss(nn.Module):\n",
        "    \"\"\"Combines Focal Loss with ordinal penalty\"\"\"\n",
        "    def __init__(self, class_weights=None, gamma=2.0, ordinal_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.focal_loss = FocalLoss(alpha=class_weights, gamma=gamma)\n",
        "        self.ordinal_weight = ordinal_weight\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Focal loss for imbalance\n",
        "        focal = self.focal_loss(logits, labels)\n",
        "\n",
        "        # Ordinal penalty\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        ordinal_penalty = torch.abs(preds.float() - labels.float()).mean()\n",
        "\n",
        "        return focal + self.ordinal_weight * ordinal_penalty\n",
        "\n",
        "# ============================================================\n",
        "# 8. TRAINING FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, criterion, device, accumulation_steps=2):\n",
        "    \"\"\"Train with gradient accumulation for effective larger batch size\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Normalize loss for accumulation\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient accumulation\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * accumulation_steps\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        progress_bar.set_postfix({'loss': f'{loss.item() * accumulation_steps:.4f}'})\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "    return avg_loss, accuracy, mae\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "    return avg_loss, accuracy, mae, all_preds, all_labels, all_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdnLHsbW-pfe"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"IMPROVED TRAINING WITH BETTER TECHNIQUES\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# BETTER HYPERPARAMETERS\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 16  # Larger batch with gradient accumulation\n",
        "ACCUMULATION_STEPS = 2  # Effective batch size = 16 * 2 = 32\n",
        "\n",
        "print(\"\\nCreating datasets...\")\n",
        "train_dataset = CSSRSDataset(train_df['text'].values, train_df['label_id'].values, tokenizer, MAX_LENGTH)\n",
        "val_dataset = CSSRSDataset(val_df['text'].values, val_df['label_id'].values, tokenizer, MAX_LENGTH)\n",
        "test_dataset = CSSRSDataset(test_df['text'].values, test_df['label_id'].values, tokenizer, MAX_LENGTH)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"✓ Train batches: {len(train_loader)} (effective batch size: {BATCH_SIZE * ACCUMULATION_STEPS})\")\n",
        "print(f\"✓ Val batches: {len(val_loader)}\")\n",
        "print(f\"✓ Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Initialize improved model\n",
        "print(f\"\\nInitializing improved model...\")\n",
        "model = OrdinalCSSRSClassifier(MODEL_NAME, num_classes=5, dropout=0.2)\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# RECALCULATE CLASS WEIGHTS - MORE MODERATE\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RECALCULATING CLASS WEIGHTS (More Balanced)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Use sqrt smoothing to make weights less aggressive\n",
        "class_counts = train_df['label_id'].value_counts().sort_index()\n",
        "total = len(train_df)\n",
        "\n",
        "new_class_weights = []\n",
        "for i in range(5):\n",
        "    count = class_counts.get(i, 1)\n",
        "    weight = np.sqrt(total / (5 * count))  # sqrt smoothing\n",
        "    new_class_weights.append(weight)\n",
        "\n",
        "new_class_weights = torch.FloatTensor(new_class_weights).to(device)\n",
        "print(\"New class weights (sqrt-smoothed):\")\n",
        "for i, weight in enumerate(new_class_weights):\n",
        "    print(f\"  {id_to_label[i]:12s}: {weight:.3f} (count: {class_counts.get(i, 0)})\")\n",
        "\n",
        "# ============================================================\n",
        "# IMPROVED TRAINING CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 3e-5  # Slightly higher for better convergence\n",
        "WARMUP_RATIO = 0.15\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * ACCUMULATION_STEPS})\")\n",
        "print(f\"Gradient accumulation steps: {ACCUMULATION_STEPS}\")\n",
        "print(f\"Warmup ratio: {WARMUP_RATIO}\")\n",
        "\n",
        "# Use Focal Loss instead of simple weighted CE\n",
        "criterion = ImprovedOrdinalLoss(\n",
        "    class_weights=new_class_weights,\n",
        "    gamma=2.0,  # Focal loss parameter\n",
        "    ordinal_weight=0.3\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "total_steps = len(train_loader) * NUM_EPOCHS\n",
        "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING IMPROVED TRAINING\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "best_val_mae = float('inf')\n",
        "best_val_acc = 0\n",
        "patience = 7  # More patience\n",
        "patience_counter = 0\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'train_mae': [],\n",
        "    'val_loss': [], 'val_acc': [], 'val_mae': []\n",
        "}\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"EPOCH {epoch + 1}/{NUM_EPOCHS}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    train_loss, train_acc, train_mae = train_epoch(\n",
        "        model, train_loader, optimizer, scheduler, criterion, device, ACCUMULATION_STEPS\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc, val_mae, val_preds, val_labels, _ = evaluate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_mae'].append(train_mae)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_mae'].append(val_mae)\n",
        "\n",
        "    print(f\"\\nTrain Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | MAE: {train_mae:.4f}\")\n",
        "    print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | MAE: {val_mae:.4f}\")\n",
        "\n",
        "    # Print validation predictions distribution\n",
        "    val_pred_dist = np.bincount(val_preds, minlength=5)\n",
        "    print(f\"Val predictions: {val_pred_dist}\")\n",
        "\n",
        "    # Save if better\n",
        "    if val_mae < best_val_mae:\n",
        "        best_val_mae = val_mae\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_mae': val_mae,\n",
        "            'val_acc': val_acc,\n",
        "        }, 'best_cssrs_model_v2.pt')\n",
        "        print(f\"✓ New best MAE! Model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TRAINING COMPLETED\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Best validation MAE: {best_val_mae:.4f}\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# FINAL EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "checkpoint = torch.load('best_cssrs_model_v2.pt', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"✓ Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
        "\n",
        "test_loss, test_acc, test_mae, test_preds, test_labels, test_probs = evaluate(\n",
        "    model, test_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(classification_report(\n",
        "    test_labels,\n",
        "    test_preds,\n",
        "    target_names=[id_to_label[i] for i in range(5)],\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "print(\"          \", \" \".join([f\"{id_to_label[i]:>10s}\" for i in range(5)]))\n",
        "for i, row in enumerate(cm):\n",
        "    print(f\"{id_to_label[i]:>10s}\", \" \".join([f\"{val:>10d}\" for val in row]))\n",
        "\n",
        "ordinal_distances = np.abs(np.array(test_preds) - np.array(test_labels))\n",
        "print(f\"\\nOrdinal Distance Analysis:\")\n",
        "print(f\"  Exact match: {np.sum(ordinal_distances == 0)} ({np.mean(ordinal_distances == 0)*100:.1f}%)\")\n",
        "print(f\"  Off by 1: {np.sum(ordinal_distances == 1)} ({np.mean(ordinal_distances == 1)*100:.1f}%)\")\n",
        "print(f\"  Off by 2: {np.sum(ordinal_distances == 2)} ({np.mean(ordinal_distances == 2)*100:.1f}%)\")\n",
        "print(f\"  Off by 3+: {np.sum(ordinal_distances >= 3)} ({np.mean(ordinal_distances >= 3)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PER-CLASS PERFORMANCE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for i in range(5):\n",
        "    mask = np.array(test_labels) == i\n",
        "    if mask.sum() > 0:\n",
        "        class_acc = np.mean(np.array(test_preds)[mask] == i)\n",
        "        class_mae = mean_absolute_error(np.array(test_labels)[mask], np.array(test_preds)[mask])\n",
        "        recall = class_acc\n",
        "        support = mask.sum()\n",
        "        print(f\"{id_to_label[i]:12s}: Acc={class_acc:.3f}, MAE={class_mae:.3f}, Support={support:2d}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL READY FOR MALAYALAM TRANSFER\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2adw4CAVA4-M"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"\\nConfusion Matrix (rows=true, cols=predicted):\")\n",
        "print(cm)\n",
        "\n",
        "# Ordinal confusion analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ORDINAL ERROR ANALYSIS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "errors = all_preds - all_labels\n",
        "print(f\"Exact matches:        {np.sum(errors == 0):3d} ({np.mean(errors == 0)*100:5.1f}%)\")\n",
        "print(f\"Off by 1:             {np.sum(np.abs(errors) == 1):3d} ({np.mean(np.abs(errors) == 1)*100:5.1f}%)\")\n",
        "print(f\"Off by 2:             {np.sum(np.abs(errors) == 2):3d} ({np.mean(np.abs(errors) == 2)*100:5.1f}%)\")\n",
        "print(f\"Off by 3+:            {np.sum(np.abs(errors) >= 3):3d} ({np.mean(np.abs(errors) >= 3)*100:5.1f}%)\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='RdYlGn_r',  # Red for errors, green for correct\n",
        "    xticklabels=list(label_to_id.keys()),\n",
        "    yticklabels=list(label_to_id.keys()),\n",
        "    cbar_kws={'label': 'Count'}\n",
        ")\n",
        "plt.title('Confusion Matrix - Ordinal Suicidality Classification\\n(Diagonal = Correct, Off-diagonal = Errors)',\n",
        "          fontsize=14, pad=20)\n",
        "plt.ylabel('True Severity Level', fontsize=12)\n",
        "plt.xlabel('Predicted Severity Level', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix_ordinal.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Confusion matrix saved as 'confusion_matrix_ordinal.png'\")\n",
        "\n",
        "# ============================================================\n",
        "# 14. PER-CLASS DETAILED ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PER-CLASS DETAILED PERFORMANCE\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for label_id in sorted(label_to_id.values()):\n",
        "    label_name = id_to_label[label_id]\n",
        "\n",
        "    # Get metrics for this class\n",
        "    mask_true = all_labels == label_id\n",
        "    mask_pred = all_preds == label_id\n",
        "\n",
        "    true_count = mask_true.sum()\n",
        "    pred_count = mask_pred.sum()\n",
        "\n",
        "    if true_count > 0:\n",
        "        # True positives\n",
        "        tp = np.sum(mask_true & mask_pred)\n",
        "\n",
        "        # Class-specific accuracy (how many of this class were correctly predicted)\n",
        "        class_acc = tp / true_count if true_count > 0 else 0\n",
        "\n",
        "        # F1 score\n",
        "        f1 = f1_score(all_labels, all_preds, labels=[label_id], average='macro', zero_division=0)\n",
        "\n",
        "        # Average predicted probability for this class\n",
        "        avg_prob_true = all_probs[mask_true, label_id].mean() if true_count > 0 else 0\n",
        "\n",
        "        # Where did misclassifications go?\n",
        "        misclassified = all_preds[mask_true & ~mask_pred]\n",
        "\n",
        "        print(f\"\\n{label_name.upper()} (Level {label_id})\")\n",
        "        print(f\"  Support (test set):       {true_count:3d}\")\n",
        "        print(f\"  Correctly predicted:      {tp:3d} / {true_count:3d} ({class_acc*100:5.1f}%)\")\n",
        "        print(f\"  F1 Score:                 {f1:.4f}\")\n",
        "        print(f\"  Avg confidence (correct): {avg_prob_true:.4f}\")\n",
        "\n",
        "        if len(misclassified) > 0:\n",
        "            print(f\"  Misclassification pattern:\")\n",
        "            for wrong_label_id, count in Counter(misclassified).most_common():\n",
        "                wrong_label_name = id_to_label[wrong_label_id]\n",
        "                distance = abs(wrong_label_id - label_id)\n",
        "                print(f\"    → {wrong_label_name:12s} (distance={distance}): {count:2d} samples\")\n",
        "\n",
        "# ============================================================\n",
        "# 15. CRITICAL METRICS FOR ATTEMPT CLASS (MOST IMPORTANT)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CRITICAL ANALYSIS: ATTEMPT CLASS (Most Severe, Only 45 samples)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "attempt_id = label_to_id['Attempt']\n",
        "attempt_mask = all_labels == attempt_id\n",
        "attempt_count = attempt_mask.sum()\n",
        "\n",
        "if attempt_count > 0:\n",
        "    attempt_preds = all_preds[attempt_mask]\n",
        "    attempt_correct = (attempt_preds == attempt_id).sum()\n",
        "    attempt_recall = attempt_correct / attempt_count\n",
        "\n",
        "    print(f\"Total Attempt samples in test set: {attempt_count}\")\n",
        "    print(f\"Correctly identified:               {attempt_correct} ({attempt_recall*100:.1f}%)\")\n",
        "    print(f\"Missed Attempts:                    {attempt_count - attempt_correct}\")\n",
        "\n",
        "    # Where were Attempts misclassified?\n",
        "    missed_attempts = attempt_preds[attempt_preds != attempt_id]\n",
        "    if len(missed_attempts) > 0:\n",
        "        print(f\"\\nMisclassification breakdown:\")\n",
        "        for pred_id, count in Counter(missed_attempts).most_common():\n",
        "            pred_name = id_to_label[pred_id]\n",
        "            distance = abs(pred_id - attempt_id)\n",
        "            risk = \"HIGH RISK\" if distance >= 2 else \"Moderate\"\n",
        "            print(f\"  → Predicted as {pred_name:12s} (distance={distance}, {risk}): {count} samples\")\n",
        "\n",
        "    # How many non-Attempts were falsely predicted as Attempts?\n",
        "    non_attempt_mask = all_labels != attempt_id\n",
        "    false_attempts = np.sum((all_preds[non_attempt_mask] == attempt_id))\n",
        "    print(f\"\\nFalse Attempt predictions (false positives): {false_attempts}\")\n",
        "\n",
        "    # Precision for Attempt class\n",
        "    if (attempt_preds == attempt_id).sum() + false_attempts > 0:\n",
        "        attempt_precision = attempt_correct / ((attempt_preds == attempt_id).sum() + false_attempts)\n",
        "        print(f\"Attempt Precision: {attempt_precision:.4f}\")\n",
        "else:\n",
        "    print(\"⚠ No Attempt samples in test set\")\n",
        "\n",
        "# ============================================================\n",
        "# 16. ERROR DISTANCE DISTRIBUTION\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ERROR DISTANCE DISTRIBUTION (Ordinal Penalty Analysis)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "error_distances = np.abs(all_preds - all_labels)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(error_distances, bins=np.arange(-0.5, 5.5, 1), edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Prediction Error Distance (|predicted - true|)', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Distribution of Ordinal Prediction Errors', fontsize=14)\n",
        "plt.xticks(range(5))\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('error_distribution.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✓ Error distribution plot saved as 'error_distribution.png'\")\n",
        "\n",
        "for dist in range(5):\n",
        "    count = np.sum(error_distances == dist)\n",
        "    pct = count / len(error_distances) * 100\n",
        "    severity = [\"Perfect\", \"Minor\", \"Moderate\", \"Severe\", \"Critical\"][dist]\n",
        "    print(f\"  Distance {dist} ({severity:8s}): {count:3d} ({pct:5.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 17. PROBABILITY CALIBRATION ANALYSIS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREDICTION CONFIDENCE ANALYSIS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Average confidence for correct vs incorrect predictions\n",
        "correct_mask = all_preds == all_labels\n",
        "incorrect_mask = ~correct_mask\n",
        "\n",
        "correct_confidence = all_probs[correct_mask, all_preds[correct_mask]].mean()\n",
        "incorrect_confidence = all_probs[incorrect_mask, all_preds[incorrect_mask]].mean()\n",
        "\n",
        "print(f\"Average confidence (correct predictions):   {correct_confidence:.4f}\")\n",
        "print(f\"Average confidence (incorrect predictions): {incorrect_confidence:.4f}\")\n",
        "print(f\"Confidence gap:                             {correct_confidence - incorrect_confidence:.4f}\")\n",
        "\n",
        "# Per-class average confidence\n",
        "print(\"\\nPer-class average prediction confidence:\")\n",
        "for label_id in sorted(label_to_id.values()):\n",
        "    label_name = id_to_label[label_id]\n",
        "    mask = all_preds == label_id\n",
        "    if mask.sum() > 0:\n",
        "        avg_conf = all_probs[mask, label_id].mean()\n",
        "        print(f\"  {label_name:12s}: {avg_conf:.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 18. SAVE MODEL AND ARTIFACTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING MODEL AND ARTIFACTS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Save MURIL encoder\n",
        "model.muril.save_pretrained('./muril_suicide_ordinal_final')\n",
        "tokenizer.save_pretrained('./muril_suicide_ordinal_final')\n",
        "\n",
        "# Save full model state dict\n",
        "torch.save(model.state_dict(), './muril_suicide_ordinal_final/full_model.pt')\n",
        "\n",
        "# Save label mappings and metadata\n",
        "import json\n",
        "\n",
        "metadata = {\n",
        "    'label_to_id': label_to_id,\n",
        "    'id_to_label': id_to_label,\n",
        "    'num_labels': NUM_LABELS,\n",
        "    'max_length': MAX_LENGTH,\n",
        "    'model_name': MODEL_NAME,\n",
        "    'class_weights': class_weights.cpu().numpy().tolist(),\n",
        "    'training_info': {\n",
        "        'total_samples': len(df),\n",
        "        'train_samples': len(train_df),\n",
        "        'val_samples': len(val_df),\n",
        "        'test_samples': len(test_df),\n",
        "        'label_distribution': label_counts.to_dict()\n",
        "    },\n",
        "    'final_metrics': {\n",
        "        'accuracy': float(accuracy_score(all_labels, all_preds)),\n",
        "        'f1_macro': float(f1_score(all_labels, all_preds, average='macro', zero_division=0)),\n",
        "        'mae': float(mean_absolute_error(all_labels, all_preds)),\n",
        "        'qwk': float(cohen_kappa_score(all_labels, all_preds, weights='quadratic')),\n",
        "        'off_by_one_acc': float(np.mean(np.abs(all_preds - all_labels) <= 1))\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('./muril_suicide_ordinal_final/metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(\"✓ MURIL encoder saved to './muril_suicide_ordinal_final'\")\n",
        "print(\"✓ Full model state_dict saved\")\n",
        "print(\"✓ Tokenizer saved\")\n",
        "print(\"✓ Metadata and label mappings saved\")\n",
        "\n",
        "# ============================================================\n",
        "# 19. EXAMPLE PREDICTIONS WITH CONFIDENCE\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE PREDICTIONS (with confidence scores)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Sample predictions from each severity level\n",
        "for target_label_id in sorted(label_to_id.values()):\n",
        "    target_label_name = id_to_label[target_label_id]\n",
        "    target_indices = test_df[test_df['label_id'] == target_label_id].index.tolist()\n",
        "\n",
        "    if len(target_indices) > 0:\n",
        "        # Get one example from this class\n",
        "        sample_idx = np.random.choice(len(target_indices))\n",
        "        df_idx = target_indices[sample_idx]\n",
        "\n",
        "        text = test_df.loc[df_idx, 'text']\n",
        "        true_label = test_df.loc[df_idx, 'label']\n",
        "\n",
        "        # Tokenize and predict\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            max_length=MAX_LENGTH,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            logits = outputs['logits']\n",
        "            probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "            pred_id = np.argmax(probs)\n",
        "            pred_label = id_to_label[pred_id]\n",
        "\n",
        "        print(f\"\\n{'-'*70}\")\n",
        "        print(f\"TRUE LABEL: {true_label.upper()} (Level {target_label_id})\")\n",
        "        print(f\"PREDICTED:  {pred_label.upper()} (Level {pred_id})\")\n",
        "        print(f\"Text: {text[:150]}...\" if len(text) > 150 else f\"Text: {text}\")\n",
        "        print(f\"\\nPrediction probabilities:\")\n",
        "        for lid in sorted(label_to_id.values()):\n",
        "            lname = id_to_label[lid]\n",
        "            prob = probs[lid]\n",
        "            bar = '█' * int(prob * 40)\n",
        "            print(f\"  {lname:12s} (L{lid}): {prob:.4f} {bar}\")\n",
        "\n",
        "# ============================================================\n",
        "# 20. CLINICAL RECOMMENDATIONS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLINICAL DEPLOYMENT RECOMMENDATIONS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"\"\"\n",
        "1. THRESHOLD ADJUSTMENT:\n",
        "   - Consider using probability thresholds rather than argmax\n",
        "   - For \"Attempt\" class (most severe), use lower threshold to increase recall\n",
        "   - Example: Flag as \"Attempt\" if P(Attempt) > 0.3 instead of 0.5\n",
        "\n",
        "2. ORDINAL CONFIDENCE:\n",
        "   - Predictions off by 1 level (e.g., Behavior→Attempt) are acceptable\n",
        "   - Focus on preventing large errors (e.g., Supportive→Attempt)\n",
        "\n",
        "3. HUMAN REVIEW TRIGGERS:\n",
        "   - Auto-flag all predictions of Behavior or Attempt for human review\n",
        "   - Flag predictions where top 2 probabilities are close (uncertain cases)\n",
        "\n",
        "4. MODEL LIMITATIONS:\n",
        "   - Small dataset (500 samples), especially for Attempt class (45 samples)\n",
        "   - Model may underpredict severe cases due to class imbalance\n",
        "   - NOT a replacement for professional mental health assessment\n",
        "\n",
        "5. ETHICAL CONSIDERATIONS:\n",
        "   - This is a screening tool, not a diagnostic tool\n",
        "   - Must be used alongside human clinical judgment\n",
        "   - Privacy and data security are paramount\n",
        "   - Consider impact of false negatives (missing severe cases)\n",
        "\n",
        "6. PERFORMANCE SUMMARY:\n",
        "   - Best at identifying Ideation (most common class)\n",
        "   - Struggles with Attempt (rarest class, only 9% of data)\n",
        "   - Ordinal structure helps reduce catastrophic errors\n",
        "   - Off-by-one accuracy shows model respects severity ordering\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING COMPLETE - MODEL READY FOR EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================\n",
        "# 21. SAVE INFERENCE SCRIPT\n",
        "# ============================================================\n",
        "\n",
        "inference_script = '''\n",
        "# INFERENCE SCRIPT FOR MURIL ORDINAL SUICIDE CLASSIFICATION\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Load model and metadata\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('./muril_suicide_ordinal_final')\n",
        "\n",
        "with open('./muril_suicide_ordinal_final/metadata.json', 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "id_to_label = {int(k): v for k, v in metadata['id_to_label'].items()}\n",
        "\n",
        "# Recreate model architecture\n",
        "from your_training_script import MURILForOrdinalSuicideClassification\n",
        "model = MURILForOrdinalSuicideClassification(\n",
        "    metadata['model_name'],\n",
        "    metadata['num_labels'],\n",
        "    dropout=0.3\n",
        ")\n",
        "model.load_state_dict(torch.load('./muril_suicide_ordinal_final/full_model.pt'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def predict_suicidality(text, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predict suicidality level for given text\n",
        "\n",
        "    Args:\n",
        "        text: Input text (Reddit post, message, etc.)\n",
        "        threshold: Probability threshold for high-risk flagging\n",
        "\n",
        "    Returns:\n",
        "        dict with prediction, probabilities, and risk level\n",
        "    \"\"\"\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=metadata['max_length'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        logits = outputs['logits']\n",
        "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "    pred_id = np.argmax(probs)\n",
        "    pred_label = id_to_label[pred_id]\n",
        "    confidence = probs[pred_id]\n",
        "\n",
        "    # Risk assessment\n",
        "    risk_level = \"LOW\" if pred_id <= 1 else \"MODERATE\" if pred_id == 2 else \"HIGH\"\n",
        "\n",
        "    # Flag for human review if high severity or uncertain\n",
        "    needs_review = (pred_id >= 3) or (confidence < 0.6)\n",
        "\n",
        "    return {\n",
        "        'predicted_level': pred_id,\n",
        "        'predicted_label': pred_label,\n",
        "        'confidence': float(confidence),\n",
        "        'risk_level': risk_level,\n",
        "        'needs_human_review': needs_review,\n",
        "        'all_probabilities': {id_to_label[i]: float(probs[i]) for i in range(len(probs))}\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    test_text = \"I don't see the point anymore. Everything feels hopeless.\"\n",
        "    result = predict_suicidality(test_text)\n",
        "    print(f\"Prediction: {result['predicted_label']} (Level {result['predicted_level']})\")\n",
        "    print(f\"Confidence: {result['confidence']:.4f}\")\n",
        "    print(f\"Risk Level: {result['risk_level']}\")\n",
        "    print(f\"Needs Review: {result['needs_human_review']}\")\n",
        "'''\n",
        "\n",
        "with open('./muril_suicide_ordinal_final/inference.py', 'w') as f:\n",
        "    f.write(inference_script)\n",
        "\n",
        "print(\"\\n✓ Inference script saved to './muril_suicide_ordinal_final/inference.py'\")\n",
        "print(\"\\nAll artifacts saved. Model ready for deployment.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUIdniRUBf6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIcGLc5uCPVy"
      },
      "source": [
        "# Comprehensive Depression score predictor (Idea seems wrong. checking...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9o8CbIGCOUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc8158b-de72-4e9a-a0d6-3551a8923675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install  xgboost optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgZ9kw9VF0ud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv7NUWHdFveQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb088679-a34a-4e5c-982e-30cb15fd5068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (682, 16)\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 682 entries, 0 to 681\n",
            "Data columns (total 16 columns):\n",
            " #   Column                                                                                                                                                                    Non-Null Count  Dtype \n",
            "---  ------                                                                                                                                                                    --------------  ----- \n",
            " 0   Age                                                                                                                                                                       682 non-null    int64 \n",
            " 1   Gender                                                                                                                                                                    682 non-null    object\n",
            " 2   Little interest or pleasure in doing things                                                                                                                               682 non-null    object\n",
            " 3     Feeling down, depressed, or hopeless                                                                                                                                    682 non-null    object\n",
            " 4     Trouble falling or staying asleep, or sleeping too much                                                                                                                 682 non-null    object\n",
            " 5     Feeling tired or having little energy                                                                                                                                   682 non-null    object\n",
            " 6     Poor appetite or overeating                                                                                                                                             682 non-null    object\n",
            " 7   Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                             682 non-null    object\n",
            " 8   Trouble concentrating on things, such as reading the newspaper or watching television                                                                                     682 non-null    object\n",
            " 9   Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual    682 non-null    object\n",
            " 10  Thoughts that you would be better off dead or of hurting yourself in some way                                                                                             682 non-null    object\n",
            " 11  PHQ_Total                                                                                                                                                                 682 non-null    int64 \n",
            " 12  PHQ_Severity                                                                                                                                                              682 non-null    object\n",
            " 13  Sleep Quality                                                                                                                                                             682 non-null    object\n",
            " 14  Study Pressure                                                                                                                                                            682 non-null    object\n",
            " 15  Financial Pressure                                                                                                                                                        682 non-null    object\n",
            "dtypes: int64(2), object(14)\n",
            "memory usage: 85.4+ KB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "Age                                                                                                                                                                         0\n",
            "Gender                                                                                                                                                                      0\n",
            "Little interest or pleasure in doing things                                                                                                                                 0\n",
            "  Feeling down, depressed, or hopeless                                                                                                                                      0\n",
            "  Trouble falling or staying asleep, or sleeping too much                                                                                                                   0\n",
            "  Feeling tired or having little energy                                                                                                                                     0\n",
            "  Poor appetite or overeating                                                                                                                                               0\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                               0\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                       0\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual      0\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                               0\n",
            "PHQ_Total                                                                                                                                                                   0\n",
            "PHQ_Severity                                                                                                                                                                0\n",
            "Sleep Quality                                                                                                                                                               0\n",
            "Study Pressure                                                                                                                                                              0\n",
            "Financial Pressure                                                                                                                                                          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/PHQ9-Malayalam/PHQ-9_Dataset_5th Edition.csv')\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW2lgtUWHUNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e5c631-e046-4978-b044-6d2dfad948e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Debug: After column name strip ---\n",
            "Shape: (682, 16)\n",
            "\n",
            "--- Debug: After initial df.dropna() ---\n",
            "Shape: (682, 16)\n",
            "Age                                                                                                                                                                       0\n",
            "Gender                                                                                                                                                                    0\n",
            "Little interest or pleasure in doing things                                                                                                                               0\n",
            "Feeling down, depressed, or hopeless                                                                                                                                      0\n",
            "Trouble falling or staying asleep, or sleeping too much                                                                                                                   0\n",
            "Feeling tired or having little energy                                                                                                                                     0\n",
            "Poor appetite or overeating                                                                                                                                               0\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                             0\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                     0\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual    0\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                             0\n",
            "PHQ_Total                                                                                                                                                                 0\n",
            "PHQ_Severity                                                                                                                                                              0\n",
            "Sleep Quality                                                                                                                                                             0\n",
            "Study Pressure                                                                                                                                                            0\n",
            "Financial Pressure                                                                                                                                                        0\n",
            "dtype: int64\n",
            "\n",
            "--- Debug: Unique values in 'Little interest or pleasure in doing things' before mapping ---\n",
            "['More than half the days' 'Not at all' 'Nearly every day' 'Several days']\n",
            "\n",
            "--- Debug: Unique values in 'Feeling down, depressed, or hopeless' before mapping ---\n",
            "['Not at all' 'Nearly every day' 'Several days' 'More than half the days']\n",
            "\n",
            "--- Debug: Unique values in 'Trouble falling or staying asleep, or sleeping too much' before mapping ---\n",
            "['Not at all' 'Nearly every day' 'Several days' 'More than half the days']\n",
            "\n",
            "--- Debug: Unique values in 'Feeling tired or having little energy' before mapping ---\n",
            "['Not at all' 'Nearly every day' 'Several days' 'More than half the days']\n",
            "\n",
            "--- Debug: Unique values in 'Poor appetite or overeating' before mapping ---\n",
            "['Not at all' 'Nearly every day' 'More than half the days' 'Several days']\n",
            "\n",
            "--- Debug: Unique values in 'Feeling bad about yourself—or that you are a failure or have let yourself or your family down' before mapping ---\n",
            "['Not at all' 'Several days' 'More than half the days' 'Nearly every day']\n",
            "\n",
            "--- Debug: Unique values in 'Trouble concentrating on things, such as reading the newspaper or watching television' before mapping ---\n",
            "['Not at all' 'More than half the days' 'Several days' 'Nearly every day']\n",
            "\n",
            "--- Debug: Unique values in 'Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual' before mapping ---\n",
            "['More than half the days' 'Not at all' 'Several days' 'Nearly every day']\n",
            "\n",
            "--- Debug: Unique values in 'Thoughts that you would be better off dead or of hurting yourself in some way' before mapping ---\n",
            "['Not at all' 'More than half the days' 'Several days' 'Nearly every day']\n",
            "\n",
            "--- Debug: After PHQ-9 symptom mapping ---\n",
            "Shape: (682, 16)\n",
            "Age                                                                                                                                                                       0\n",
            "Gender                                                                                                                                                                    0\n",
            "Little interest or pleasure in doing things                                                                                                                               0\n",
            "Feeling down, depressed, or hopeless                                                                                                                                      0\n",
            "Trouble falling or staying asleep, or sleeping too much                                                                                                                   0\n",
            "Feeling tired or having little energy                                                                                                                                     0\n",
            "Poor appetite or overeating                                                                                                                                               0\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                             0\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                     0\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual    0\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                             0\n",
            "PHQ_Total                                                                                                                                                                 0\n",
            "PHQ_Severity                                                                                                                                                              0\n",
            "Sleep Quality                                                                                                                                                             0\n",
            "Study Pressure                                                                                                                                                            0\n",
            "Financial Pressure                                                                                                                                                        0\n",
            "dtype: int64\n",
            "\n",
            "--- Debug: Unique values in 'Gender' before mapping ---\n",
            "['Male' 'Female']\n",
            "\n",
            "--- Debug: Unique values in 'Sleep Quality' before mapping ---\n",
            "['Good' 'Worst' 'Average' 'Bad']\n",
            "\n",
            "--- Debug: Unique values in 'Study Pressure' before mapping ---\n",
            "['Good' 'Bad' 'Average' 'Worst']\n",
            "\n",
            "--- Debug: Unique values in 'Financial Pressure' before mapping ---\n",
            "['Average' 'Worst' 'Good' 'Bad']\n",
            "\n",
            "--- Debug: After all categorical mappings ---\n",
            "Shape: (682, 16)\n",
            "Age                                                                                                                                                                         0\n",
            "Gender                                                                                                                                                                      0\n",
            "Little interest or pleasure in doing things                                                                                                                                 0\n",
            "Feeling down, depressed, or hopeless                                                                                                                                        0\n",
            "Trouble falling or staying asleep, or sleeping too much                                                                                                                     0\n",
            "Feeling tired or having little energy                                                                                                                                       0\n",
            "Poor appetite or overeating                                                                                                                                                 0\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                               0\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                       0\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual      0\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                               0\n",
            "PHQ_Total                                                                                                                                                                   0\n",
            "PHQ_Severity                                                                                                                                                                0\n",
            "Sleep Quality                                                                                                                                                               0\n",
            "Study Pressure                                                                                                                                                            107\n",
            "Financial Pressure                                                                                                                                                        104\n",
            "dtype: int64\n",
            "\n",
            "--- Debug: Before final df.dropna() ---\n",
            "Shape: (682, 15)\n",
            "Age                                                                                                                                                                         0\n",
            "Gender                                                                                                                                                                      0\n",
            "Little interest or pleasure in doing things                                                                                                                                 0\n",
            "Feeling down, depressed, or hopeless                                                                                                                                        0\n",
            "Trouble falling or staying asleep, or sleeping too much                                                                                                                     0\n",
            "Feeling tired or having little energy                                                                                                                                       0\n",
            "Poor appetite or overeating                                                                                                                                                 0\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                               0\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                       0\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual      0\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                               0\n",
            "PHQ_Total                                                                                                                                                                   0\n",
            "Sleep Quality                                                                                                                                                               0\n",
            "Study Pressure                                                                                                                                                            107\n",
            "Financial Pressure                                                                                                                                                        104\n",
            "dtype: int64\n",
            "\n",
            "Data after preprocessing:\n",
            "   Age  Gender  Little interest or pleasure in doing things  \\\n",
            "0   22       0                                            2   \n",
            "1   25       0                                            0   \n",
            "2   22       1                                            0   \n",
            "3   24       0                                            0   \n",
            "4   19       0                                            0   \n",
            "\n",
            "   Feeling down, depressed, or hopeless  \\\n",
            "0                                     0   \n",
            "1                                     0   \n",
            "2                                     0   \n",
            "3                                     0   \n",
            "4                                     0   \n",
            "\n",
            "   Trouble falling or staying asleep, or sleeping too much  \\\n",
            "0                                                  0         \n",
            "1                                                  3         \n",
            "2                                                  0         \n",
            "3                                                  0         \n",
            "4                                                  0         \n",
            "\n",
            "   Feeling tired or having little energy  Poor appetite or overeating  \\\n",
            "0                                      0                            0   \n",
            "1                                      3                            3   \n",
            "2                                      0                            0   \n",
            "3                                      0                            0   \n",
            "4                                      0                            0   \n",
            "\n",
            "   Feeling bad about yourself—or that you are a failure or have let yourself or your family down  \\\n",
            "0                                                  0                                               \n",
            "1                                                  0                                               \n",
            "2                                                  0                                               \n",
            "3                                                  0                                               \n",
            "4                                                  0                                               \n",
            "\n",
            "   Trouble concentrating on things, such as reading the newspaper or watching television  \\\n",
            "0                                                  0                                       \n",
            "1                                                  2                                       \n",
            "2                                                  1                                       \n",
            "3                                                  0                                       \n",
            "4                                                  0                                       \n",
            "\n",
            "   Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual  \\\n",
            "0                                                  2                                                                                                                        \n",
            "1                                                  2                                                                                                                        \n",
            "2                                                  0                                                                                                                        \n",
            "3                                                  2                                                                                                                        \n",
            "4                                                  0                                                                                                                        \n",
            "\n",
            "   Thoughts that you would be better off dead or of hurting yourself in some way  \\\n",
            "0                                                  0                               \n",
            "1                                                  2                               \n",
            "2                                                  0                               \n",
            "3                                                  0                               \n",
            "4                                                  0                               \n",
            "\n",
            "   PHQ_Total  Sleep Quality  Study Pressure  Financial Pressure  \n",
            "0          4              0             0.0                 1.0  \n",
            "1         15              3             2.0                 1.0  \n",
            "2          1              1             2.0                 1.0  \n",
            "3          2              0             1.0                 0.0  \n",
            "4          0              0             0.0                 0.0  \n",
            "\n",
            "Data types:\n",
            "Age                                                                                                                                                                         int64\n",
            "Gender                                                                                                                                                                      int64\n",
            "Little interest or pleasure in doing things                                                                                                                                 int64\n",
            "Feeling down, depressed, or hopeless                                                                                                                                        int64\n",
            "Trouble falling or staying asleep, or sleeping too much                                                                                                                     int64\n",
            "Feeling tired or having little energy                                                                                                                                       int64\n",
            "Poor appetite or overeating                                                                                                                                                 int64\n",
            "Feeling bad about yourself—or that you are a failure or have let yourself or your family down                                                                               int64\n",
            "Trouble concentrating on things, such as reading the newspaper or watching television                                                                                       int64\n",
            "Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual      int64\n",
            "Thoughts that you would be better off dead or of hurting yourself in some way                                                                                               int64\n",
            "PHQ_Total                                                                                                                                                                   int64\n",
            "Sleep Quality                                                                                                                                                               int64\n",
            "Study Pressure                                                                                                                                                            float64\n",
            "Financial Pressure                                                                                                                                                        float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# DATA PREPROCESSING\n",
        "# ============================================\n",
        "\n",
        "# Clean column names (remove extra spaces)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(\"\\n--- Debug: After column name strip ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "\n",
        "# Handle missing values - initial dropna\n",
        "df = df.dropna()\n",
        "print(\"\\n--- Debug: After initial df.dropna() ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Define PHQ-9 symptom columns\n",
        "phq_symptoms = [\n",
        "    'Little interest or pleasure in doing things',\n",
        "    'Feeling down, depressed, or hopeless',\n",
        "    'Trouble falling or staying asleep, or sleeping too much',\n",
        "    'Feeling tired or having little energy',\n",
        "    'Poor appetite or overeating',\n",
        "    'Feeling bad about yourself—or that you are a failure or have let yourself or your family down',\n",
        "    'Trouble concentrating on things, such as reading the newspaper or watching television',\n",
        "    'Moving or speaking so slowly that other people could have noticed? Or the opposite—being so fidgety or restless that you have been moving around a lot more than usual',\n",
        "    'Thoughts that you would be better off dead or of hurting yourself in some way'\n",
        "]\n",
        "\n",
        "# Create ordinal mapping for PHQ-9 symptoms\n",
        "symptom_mapping = {\n",
        "    'Not at all': 0,\n",
        "    'Several days': 1,\n",
        "    'More than half the days': 2,\n",
        "    'Nearly every day': 3\n",
        "}\n",
        "\n",
        "# Encode PHQ-9 symptoms\n",
        "for col in phq_symptoms:\n",
        "    if col in df.columns:\n",
        "        print(f\"\\n--- Debug: Unique values in '{col}' before mapping ---\")\n",
        "        print(df[col].astype(str).str.strip().unique())\n",
        "        df[col] = df[col].astype(str).str.strip().map(symptom_mapping)\n",
        "print(\"\\n--- Debug: After PHQ-9 symptom mapping ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Encode categorical variables\n",
        "# Gender\n",
        "gender_mapping = {'Male': 0, 'Female': 1, 'Other': 2}\n",
        "print(\"\\n--- Debug: Unique values in 'Gender' before mapping ---\")\n",
        "print(df['Gender'].astype(str).str.strip().unique())\n",
        "df['Gender'] = df['Gender'].astype(str).str.strip().map(gender_mapping)\n",
        "\n",
        "# Sleep Quality\n",
        "sleep_mapping = {'Good': 0, 'Average': 1, 'Bad': 2, 'Worst': 3}\n",
        "print(\"\\n--- Debug: Unique values in 'Sleep Quality' before mapping ---\")\n",
        "print(df['Sleep Quality'].astype(str).str.strip().unique())\n",
        "df['Sleep Quality'] = df['Sleep Quality'].astype(str).str.strip().map(sleep_mapping)\n",
        "\n",
        "# Study Pressure\n",
        "study_mapping = {'Good': 0, 'Average': 1, 'Bad': 2}\n",
        "print(\"\\n--- Debug: Unique values in 'Study Pressure' before mapping ---\")\n",
        "print(df['Study Pressure'].astype(str).str.strip().unique())\n",
        "df['Study Pressure'] = df['Study Pressure'].astype(str).str.strip().map(study_mapping)\n",
        "\n",
        "# Financial Pressure\n",
        "financial_mapping = {'Good': 0, 'Average': 1, 'Bad': 2}\n",
        "print(\"\\n--- Debug: Unique values in 'Financial Pressure' before mapping ---\")\n",
        "print(df['Financial Pressure'].astype(str).str.strip().unique())\n",
        "df['Financial Pressure'] = df['Financial Pressure'].astype(str).str.strip().map(financial_mapping)\n",
        "\n",
        "print(\"\\n--- Debug: After all categorical mappings ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remove PHQ_Severity as it's derived from PHQ_Total\n",
        "if 'PHQ_Severity' in df.columns:\n",
        "    df = df.drop('PHQ_Severity', axis=1)\n",
        "\n",
        "# Ensure all columns are numeric after mapping, dropping rows with any NaNs\n",
        "# that might have been introduced by .map() if a value was not in the dictionary.\n",
        "print(\"\\n--- Debug: Before final df.dropna() ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(df.isnull().sum())\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(df.head())\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOoBu9JjGT5n"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================\n",
        "\n",
        "# Create additional features\n",
        "df['Total_Symptoms_Score'] = df[phq_symptoms].sum(axis=1)\n",
        "df['Avg_Symptom_Severity'] = df[phq_symptoms].mean(axis=1)\n",
        "df['Severe_Symptoms_Count'] = (df[phq_symptoms] >= 2).sum(axis=1)\n",
        "df['External_Stress_Score'] = df['Sleep Quality'] + df['Study Pressure'] + df['Financial Pressure']\n",
        "\n",
        "# Interaction features\n",
        "df['Sleep_Study_Interaction'] = df['Sleep Quality'] * df['Study Pressure']\n",
        "df['Age_Gender_Interaction'] = df['Age'] * df['Gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHhJtyyxGZP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875ce5ca-a07d-4f89-b958-06511563845d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set size: 402\n",
            "Test set size: 101\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# PREPARE DATA FOR MODELING\n",
        "# ============================================\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('PHQ_Total', axis=1)\n",
        "y = df['PHQ_Total']\n",
        "\n",
        "# Add a final check for NaNs after feature engineering\n",
        "# and before splitting and scaling, just to be safe.\n",
        "# This also handles any potential NaNs created during feature engineering\n",
        "# (though unlikely with the current operations).\n",
        "combined_df = pd.concat([X, y], axis=1)\n",
        "combined_df = combined_df.dropna().reset_index(drop=True)\n",
        "X = combined_df.drop('PHQ_Total', axis=1)\n",
        "y = combined_df['PHQ_Total']\n",
        "\n",
        "\n",
        "# Identify and remove zero-variance columns before scaling\n",
        "# These columns cause StandardScaler to produce NaNs\n",
        "zero_variance_cols = X.columns[X.var() == 0]\n",
        "if not zero_variance_cols.empty:\n",
        "    print(f\"Warning: Removing zero-variance columns: {list(zero_variance_cols)}\")\n",
        "    X = X.drop(columns=zero_variance_cols)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGTm6t5gGf0R"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# OPTUNA OPTIMIZATION\n",
        "# ============================================\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"Objective function for Optuna optimization\"\"\"\n",
        "\n",
        "    # Suggest which model to use\n",
        "    model_name = trial.suggest_categorical('model', ['xgboost', 'random_forest', 'gradient_boosting', 'ridge'])\n",
        "\n",
        "    if model_name == 'xgboost':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = XGBRegressor(**params)\n",
        "\n",
        "    elif model_name == 'random_forest':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = RandomForestRegressor(**params)\n",
        "\n",
        "    elif model_name == 'gradient_boosting':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = GradientBoostingRegressor(**params)\n",
        "\n",
        "    else:  # ridge\n",
        "        params = {\n",
        "            'alpha': trial.suggest_float('alpha', 0.01, 100, log=True),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = Ridge(**params)\n",
        "\n",
        "    # Cross-validation score\n",
        "    cv_scores = cross_val_score(\n",
        "        model, X_train_scaled, y_train,\n",
        "        cv=5, scoring='neg_mean_squared_error'\n",
        "    )\n",
        "\n",
        "    return -cv_scores.mean()  # Return negative MSE (Optuna minimizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FBeI21dGqBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "18a938ed94c44e10870563b2047868de",
            "c3c4bda368a8408999498a63f72ff2cf",
            "963365977bc24a5ab660839c6e22f0cd",
            "cce270112fe4478b9bb662d6d7ef17e8",
            "330aef3364bb4ba78d549d7ad49dd0ba",
            "b9278fb5f3cb4cb2bcb31b2316461f17",
            "4677acebb0b641a3845dff0cc502fc21",
            "dc0e13e8660147548d142b7fa144ddd6",
            "ad64b755ce9947c4b77ee721e477e37a",
            "704fd368f58c42bf8ce6a7996f1ea0eb",
            "e4cea9cc6ad44bc09a265724cbd7df74"
          ]
        },
        "outputId": "90107575-e5af-4420-943a-54f4273c439b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-09 17:10:23,412] A new study created in memory with name: depression_prediction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "STARTING OPTUNA OPTIMIZATION\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18a938ed94c44e10870563b2047868de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-12-09 17:10:23,567] Trial 0 finished with value: 0.079487609547757 and parameters: {'model': 'ridge', 'alpha': 64.2705380437855}. Best is trial 0 with value: 0.079487609547757.\n",
            "[I 2025-12-09 17:10:25,339] Trial 1 finished with value: 0.05394525537267327 and parameters: {'model': 'xgboost', 'n_estimators': 76, 'max_depth': 9, 'learning_rate': 0.29096725182074706, 'subsample': 0.7871400758635652, 'colsample_bytree': 0.8774559767702512, 'min_child_weight': 7, 'gamma': 0.06873386864160907}. Best is trial 1 with value: 0.05394525537267327.\n",
            "[I 2025-12-09 17:10:26,185] Trial 2 finished with value: 0.10247377008199691 and parameters: {'model': 'xgboost', 'n_estimators': 299, 'max_depth': 10, 'learning_rate': 0.07516633620408593, 'subsample': 0.9869649454593658, 'colsample_bytree': 0.6947175630290858, 'min_child_weight': 6, 'gamma': 0.4441137980438356}. Best is trial 1 with value: 0.05394525537267327.\n",
            "[I 2025-12-09 17:10:26,248] Trial 3 finished with value: 2.5907248258146418e-06 and parameters: {'model': 'ridge', 'alpha': 0.12186293213165482}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:26,276] Trial 4 finished with value: 0.07725369145918587 and parameters: {'model': 'ridge', 'alpha': 62.83212059944587}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:27,967] Trial 5 finished with value: 0.7973168713609426 and parameters: {'model': 'random_forest', 'n_estimators': 109, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:30,719] Trial 6 finished with value: 0.6120670042003569 and parameters: {'model': 'random_forest', 'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:31,802] Trial 7 finished with value: 0.11836389154195785 and parameters: {'model': 'xgboost', 'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.09200919835561432, 'subsample': 0.7916016809239548, 'colsample_bytree': 0.6413839697567775, 'min_child_weight': 2, 'gamma': 0.35420085354966624}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:34,823] Trial 8 finished with value: 0.15969810350727437 and parameters: {'model': 'gradient_boosting', 'n_estimators': 231, 'max_depth': 5, 'learning_rate': 0.2778550759853215, 'subsample': 0.7279403329657059, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:37,452] Trial 9 finished with value: 0.0028031408807166107 and parameters: {'model': 'gradient_boosting', 'n_estimators': 85, 'max_depth': 10, 'learning_rate': 0.2578779801426338, 'subsample': 0.9434521736415177, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 2.5907248258146418e-06.\n",
            "[I 2025-12-09 17:10:37,548] Trial 10 finished with value: 3.1987812190156535e-08 and parameters: {'model': 'ridge', 'alpha': 0.01346397898082342}. Best is trial 10 with value: 3.1987812190156535e-08.\n",
            "[I 2025-12-09 17:10:37,624] Trial 11 finished with value: 2.162334832683796e-08 and parameters: {'model': 'ridge', 'alpha': 0.011068468168761236}. Best is trial 11 with value: 2.162334832683796e-08.\n",
            "[I 2025-12-09 17:10:37,714] Trial 12 finished with value: 3.302140697179801e-08 and parameters: {'model': 'ridge', 'alpha': 0.013679931108911718}. Best is trial 11 with value: 2.162334832683796e-08.\n",
            "[I 2025-12-09 17:10:37,766] Trial 13 finished with value: 2.3497772373486936e-08 and parameters: {'model': 'ridge', 'alpha': 0.011538522705225934}. Best is trial 11 with value: 2.162334832683796e-08.\n",
            "[I 2025-12-09 17:10:37,826] Trial 14 finished with value: 1.3847802442349086e-05 and parameters: {'model': 'ridge', 'alpha': 0.28412886173100227}. Best is trial 11 with value: 2.162334832683796e-08.\n",
            "[I 2025-12-09 17:10:37,865] Trial 15 finished with value: 2.06534559838308e-08 and parameters: {'model': 'ridge', 'alpha': 0.010817244220459592}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:37,961] Trial 16 finished with value: 0.0018865209570997515 and parameters: {'model': 'ridge', 'alpha': 3.910698551723414}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:40,418] Trial 17 finished with value: 0.09952651245627435 and parameters: {'model': 'gradient_boosting', 'n_estimators': 213, 'max_depth': 3, 'learning_rate': 0.017754629557171858, 'subsample': 0.6170811303587147, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:45,796] Trial 18 finished with value: 0.1655032711939603 and parameters: {'model': 'random_forest', 'n_estimators': 293, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:45,831] Trial 19 finished with value: 1.7102945185448236e-06 and parameters: {'model': 'ridge', 'alpha': 0.09889474588554592}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:45,867] Trial 20 finished with value: 0.0008392477190432297 and parameters: {'model': 'ridge', 'alpha': 2.4522122739741135}. Best is trial 15 with value: 2.06534559838308e-08.\n",
            "[I 2025-12-09 17:10:45,911] Trial 21 finished with value: 1.8732691276110722e-08 and parameters: {'model': 'ridge', 'alpha': 0.01030169040178252}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:45,965] Trial 22 finished with value: 4.476158781312209e-07 and parameters: {'model': 'ridge', 'alpha': 0.0504641974211795}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:45,993] Trial 23 finished with value: 2.391233209116317e-07 and parameters: {'model': 'ridge', 'alpha': 0.036857814744006845}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:46,040] Trial 24 finished with value: 3.035022636369866e-05 and parameters: {'model': 'ridge', 'alpha': 0.42365594448135624}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:46,109] Trial 25 finished with value: 1.316069805683249e-07 and parameters: {'model': 'ridge', 'alpha': 0.027329981442069644}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:46,664] Trial 26 finished with value: 0.00902270283550024 and parameters: {'model': 'xgboost', 'n_estimators': 172, 'max_depth': 3, 'learning_rate': 0.19523873014472992, 'subsample': 0.6002527531956436, 'colsample_bytree': 0.991703397811042, 'min_child_weight': 1, 'gamma': 0.02700454869444241}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:53,773] Trial 27 finished with value: 0.7940151213023665 and parameters: {'model': 'random_forest', 'n_estimators': 234, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:57,532] Trial 28 finished with value: 0.02105458599820993 and parameters: {'model': 'gradient_boosting', 'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.1793541450769609, 'subsample': 0.8930686206330835, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 21 with value: 1.8732691276110722e-08.\n",
            "[I 2025-12-09 17:10:57,574] Trial 29 finished with value: 1.8307740552056543e-08 and parameters: {'model': 'ridge', 'alpha': 0.010184109847759311}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:57,610] Trial 30 finished with value: 5.308095523098343e-07 and parameters: {'model': 'ridge', 'alpha': 0.05496714219712476}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:57,663] Trial 31 finished with value: 1.914750788855775e-08 and parameters: {'model': 'ridge', 'alpha': 0.010415188776511432}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:57,727] Trial 32 finished with value: 1.1509198559458266e-07 and parameters: {'model': 'ridge', 'alpha': 0.02555533918166389}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:57,764] Trial 33 finished with value: 2.0857196549821245e-08 and parameters: {'model': 'ridge', 'alpha': 0.010870498496785652}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:58,187] Trial 34 finished with value: 0.06267532519996166 and parameters: {'model': 'xgboost', 'n_estimators': 55, 'max_depth': 5, 'learning_rate': 0.11844722017936085, 'subsample': 0.6942289123512768, 'colsample_bytree': 0.8017493185880684, 'min_child_weight': 4, 'gamma': 0.1975841739218252}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:58,242] Trial 35 finished with value: 1.1994592595102194e-07 and parameters: {'model': 'ridge', 'alpha': 0.026089402187836286}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:58,275] Trial 36 finished with value: 1.8323351618419505e-06 and parameters: {'model': 'ridge', 'alpha': 0.1023810829265966}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:58,311] Trial 37 finished with value: 7.326301440014691e-08 and parameters: {'model': 'ridge', 'alpha': 0.02038368305097052}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:10:59,280] Trial 38 finished with value: 0.7541754126548768 and parameters: {'model': 'xgboost', 'n_estimators': 146, 'max_depth': 7, 'learning_rate': 0.014749319046883425, 'subsample': 0.8678946948849802, 'colsample_bytree': 0.9920292251129388, 'min_child_weight': 4, 'gamma': 0.2324661264317873}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:03,502] Trial 39 finished with value: 0.9947678710275877 and parameters: {'model': 'random_forest', 'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:03,540] Trial 40 finished with value: 0.006650129992855726 and parameters: {'model': 'ridge', 'alpha': 8.725477609512867}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:03,577] Trial 41 finished with value: 1.8697928301946354e-08 and parameters: {'model': 'ridge', 'alpha': 0.010292122124457449}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:03,609] Trial 42 finished with value: 1.9134524419813602e-08 and parameters: {'model': 'ridge', 'alpha': 0.010411655082772637}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:03,675] Trial 43 finished with value: 3.478841603838377e-07 and parameters: {'model': 'ridge', 'alpha': 0.04447445720397215}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:09,986] Trial 44 finished with value: 0.051464528572091994 and parameters: {'model': 'gradient_boosting', 'n_estimators': 258, 'max_depth': 4, 'learning_rate': 0.2191401914998239, 'subsample': 0.866605888639585, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:10,112] Trial 45 finished with value: 8.852954032374664e-08 and parameters: {'model': 'ridge', 'alpha': 0.022409436128828467}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:10,220] Trial 46 finished with value: 6.457412556677247e-08 and parameters: {'model': 'ridge', 'alpha': 0.019135545263458627}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:10,311] Trial 47 finished with value: 6.553979173405235e-07 and parameters: {'model': 'ridge', 'alpha': 0.06109795953795663}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:10,859] Trial 48 finished with value: 0.12518516927957535 and parameters: {'model': 'xgboost', 'n_estimators': 142, 'max_depth': 8, 'learning_rate': 0.1418155997313208, 'subsample': 0.6797171631381619, 'colsample_bytree': 0.7376355360802849, 'min_child_weight': 5, 'gamma': 0.4585015332897076}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:14,800] Trial 49 finished with value: 0.15855748031918215 and parameters: {'model': 'random_forest', 'n_estimators': 176, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 29 with value: 1.8307740552056543e-08.\n",
            "[I 2025-12-09 17:11:14,864] Trial 50 finished with value: 1.7697073993991416e-08 and parameters: {'model': 'ridge', 'alpha': 0.010012729657070419}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:14,903] Trial 51 finished with value: 5.554169053164256e-08 and parameters: {'model': 'ridge', 'alpha': 0.01774553779643845}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:14,975] Trial 52 finished with value: 1.991645920068663e-08 and parameters: {'model': 'ridge', 'alpha': 0.01062238040459076}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:15,060] Trial 53 finished with value: 1.509011937614257e-07 and parameters: {'model': 'ridge', 'alpha': 0.029267843143552318}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:15,172] Trial 54 finished with value: 5.828878444078514e-08 and parameters: {'model': 'ridge', 'alpha': 0.018179506732188325}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:15,270] Trial 55 finished with value: 0.0794541852887329 and parameters: {'model': 'ridge', 'alpha': 64.24912509866161}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,502] Trial 56 finished with value: 0.0444579596604726 and parameters: {'model': 'gradient_boosting', 'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.06418711351967572, 'subsample': 0.7494101089959468, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,595] Trial 57 finished with value: 1.9865511538621674e-08 and parameters: {'model': 'ridge', 'alpha': 0.010608777672223981}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,699] Trial 58 finished with value: 4.7161790787492224e-08 and parameters: {'model': 'ridge', 'alpha': 0.01635093889564404}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,776] Trial 59 finished with value: 2.0998512134096917e-07 and parameters: {'model': 'ridge', 'alpha': 0.03453500871227604}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,866] Trial 60 finished with value: 5.814079812920149e-06 and parameters: {'model': 'ridge', 'alpha': 0.18314360908264246}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:17,919] Trial 61 finished with value: 3.793797501187885e-08 and parameters: {'model': 'ridge', 'alpha': 0.014663776247890996}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:18,045] Trial 62 finished with value: 1.864656857459506e-08 and parameters: {'model': 'ridge', 'alpha': 0.010277969426239736}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:18,099] Trial 63 finished with value: 2.1058848502445136e-08 and parameters: {'model': 'ridge', 'alpha': 0.01092295162833405}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:18,161] Trial 64 finished with value: 4.22173911552795e-08 and parameters: {'model': 'ridge', 'alpha': 0.01546938241486692}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:18,199] Trial 65 finished with value: 0.025843438086882713 and parameters: {'model': 'ridge', 'alpha': 24.961281999840367}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:22,307] Trial 66 finished with value: 0.7486118713697694 and parameters: {'model': 'random_forest', 'n_estimators': 271, 'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:22,357] Trial 67 finished with value: 1.8101156719642012e-08 and parameters: {'model': 'ridge', 'alpha': 0.010126457355632971}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:24,000] Trial 68 finished with value: 0.0785138401455891 and parameters: {'model': 'gradient_boosting', 'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.22515934987931902, 'subsample': 0.9824786358126805, 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:24,050] Trial 69 finished with value: 4.593337413153347e-08 and parameters: {'model': 'ridge', 'alpha': 0.016136405274812676}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:24,930] Trial 70 finished with value: 0.014639456872828305 and parameters: {'model': 'xgboost', 'n_estimators': 203, 'max_depth': 6, 'learning_rate': 0.15092722298618233, 'subsample': 0.9228544841310274, 'colsample_bytree': 0.8676756376664265, 'min_child_weight': 2, 'gamma': 0.15196584054688478}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:24,981] Trial 71 finished with value: 1.838733421482166e-08 and parameters: {'model': 'ridge', 'alpha': 0.0102062357234556}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,085] Trial 72 finished with value: 0.00011702604998959009 and parameters: {'model': 'ridge', 'alpha': 0.8498513611725678}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,189] Trial 73 finished with value: 1.9182842623475938e-08 and parameters: {'model': 'ridge', 'alpha': 0.010424799729197728}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,270] Trial 74 finished with value: 4.391063121721227e-08 and parameters: {'model': 'ridge', 'alpha': 0.015776809784011834}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,320] Trial 75 finished with value: 9.12922103526449e-07 and parameters: {'model': 'ridge', 'alpha': 0.07215126050312538}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,370] Trial 76 finished with value: 2.2757643116116152e-07 and parameters: {'model': 'ridge', 'alpha': 0.035955186328216183}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,458] Trial 77 finished with value: 8.933871177683016e-08 and parameters: {'model': 'ridge', 'alpha': 0.022511737611127743}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,492] Trial 78 finished with value: 3.624197717682649e-08 and parameters: {'model': 'ridge', 'alpha': 0.014332008692743646}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:25,538] Trial 79 finished with value: 1.4515993813644883e-07 and parameters: {'model': 'ridge', 'alpha': 0.028704820687353513}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:30,638] Trial 80 finished with value: 0.06248849369436551 and parameters: {'model': 'random_forest', 'n_estimators': 170, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:30,693] Trial 81 finished with value: 1.781901835139527e-08 and parameters: {'model': 'ridge', 'alpha': 0.010047185887743454}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:30,755] Trial 82 finished with value: 1.7896194239453176e-08 and parameters: {'model': 'ridge', 'alpha': 0.010068931646669147}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:30,858] Trial 83 finished with value: 3.4238549666852276e-08 and parameters: {'model': 'ridge', 'alpha': 0.013929949888015342}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:30,930] Trial 84 finished with value: 7.685672180208687e-08 and parameters: {'model': 'ridge', 'alpha': 0.020878176277226348}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:31,012] Trial 85 finished with value: 3.2930021604303395e-08 and parameters: {'model': 'ridge', 'alpha': 0.013660974959577438}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:31,048] Trial 86 finished with value: 1.8613864452136294e-08 and parameters: {'model': 'ridge', 'alpha': 0.010268947322761122}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:31,121] Trial 87 finished with value: 9.315568428069151e-08 and parameters: {'model': 'ridge', 'alpha': 0.02298819139357314}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:32,031] Trial 88 finished with value: 0.1787346065044403 and parameters: {'model': 'xgboost', 'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.05120246198826982, 'subsample': 0.6675701499999782, 'colsample_bytree': 0.6003895792280584, 'min_child_weight': 7, 'gamma': 0.3302901524569776}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,581] Trial 89 finished with value: 0.08686811982335915 and parameters: {'model': 'gradient_boosting', 'n_estimators': 80, 'max_depth': 4, 'learning_rate': 0.1162699905485485, 'subsample': 0.8277151830061567, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,629] Trial 90 finished with value: 2.9623526652332156e-07 and parameters: {'model': 'ridge', 'alpha': 0.04103295397248105}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,671] Trial 91 finished with value: 1.774335623048924e-08 and parameters: {'model': 'ridge', 'alpha': 0.010025820947314499}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,753] Trial 92 finished with value: 3.311046114941516e-08 and parameters: {'model': 'ridge', 'alpha': 0.01369837851565543}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,789] Trial 93 finished with value: 1.879112930258908e-08 and parameters: {'model': 'ridge', 'alpha': 0.01031775511672618}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,881] Trial 94 finished with value: 6.997108760164923e-08 and parameters: {'model': 'ridge', 'alpha': 0.01991998098184839}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,911] Trial 95 finished with value: 3.231499193103281e-08 and parameters: {'model': 'ridge', 'alpha': 0.013532709622544953}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:33,986] Trial 96 finished with value: 1.224071135627835e-07 and parameters: {'model': 'ridge', 'alpha': 0.026356080888610533}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:34,027] Trial 97 finished with value: 3.1260139181902024e-08 and parameters: {'model': 'ridge', 'alpha': 0.013309847041869364}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:34,069] Trial 98 finished with value: 0.0010847110044475904 and parameters: {'model': 'ridge', 'alpha': 2.834835021244525}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "[I 2025-12-09 17:11:34,119] Trial 99 finished with value: 6.016425269081324e-08 and parameters: {'model': 'ridge', 'alpha': 0.01846994220623438}. Best is trial 50 with value: 1.7697073993991416e-08.\n",
            "\n",
            "==================================================\n",
            "OPTIMIZATION COMPLETE\n",
            "==================================================\n",
            "\n",
            "Best trial value (MSE): 0.0000\n",
            "Best trial RMSE: 0.0001\n",
            "\n",
            "Best hyperparameters:\n",
            "  model: ridge\n",
            "  alpha: 0.010012729657070419\n",
            "\n",
            "==================================================\n",
            "TRAINING FINAL MODEL: RIDGE\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.010012729657070419, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.010012729657070419, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ridge</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.010012729657070419, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Run Optuna optimization\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STARTING OPTUNA OPTIMIZATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "study = optuna.create_study(direction='minimize', study_name='depression_prediction')\n",
        "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"OPTIMIZATION COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nBest trial value (MSE): {study.best_trial.value:.4f}\")\n",
        "print(f\"Best trial RMSE: {np.sqrt(study.best_trial.value):.4f}\")\n",
        "print(\"\\nBest hyperparameters:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# ============================================\n",
        "# TRAIN FINAL MODEL WITH BEST PARAMETERS\n",
        "# ============================================\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "model_name = best_params.pop('model')\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"TRAINING FINAL MODEL: {model_name.upper()}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "if model_name == 'xgboost':\n",
        "    best_params['random_state'] = 42\n",
        "    final_model = XGBRegressor(**best_params)\n",
        "elif model_name == 'random_forest':\n",
        "    best_params['random_state'] = 42\n",
        "    final_model = RandomForestRegressor(**best_params)\n",
        "elif model_name == 'gradient_boosting':\n",
        "    best_params['random_state'] = 42\n",
        "    final_model = GradientBoostingRegressor(**best_params)\n",
        "else:\n",
        "    best_params['random_state'] = 42\n",
        "    final_model = Ridge(**best_params)\n",
        "\n",
        "# Train final model\n",
        "final_model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgncOVNJGupH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce880abb-3aca-414e-d905-95f482332391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MODEL PERFORMANCE\n",
            "==================================================\n",
            "\n",
            "Training Set:\n",
            "  RMSE: 0.0001\n",
            "  MAE:  0.0001\n",
            "  R²:   1.0000\n",
            "\n",
            "Test Set:\n",
            "  RMSE: 0.0001\n",
            "  MAE:  0.0001\n",
            "  R²:   1.0000\n",
            "\n",
            "==================================================\n",
            "SAMPLE PREDICTIONS\n",
            "==================================================\n",
            " Actual  Predicted  Difference\n",
            "     18  18.000084   -0.000084\n",
            "      0   0.000130   -0.000130\n",
            "      7   6.999848    0.000152\n",
            "     12  11.999976    0.000024\n",
            "      0   0.000167   -0.000167\n",
            "      9   9.000035   -0.000035\n",
            "     22  22.000028   -0.000028\n",
            "      4   3.999891    0.000109\n",
            "      0   0.000166   -0.000166\n",
            "      6   6.000095   -0.000095\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# MODEL EVALUATION\n",
        "# ============================================\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = final_model.predict(X_train_scaled)\n",
        "y_test_pred = final_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"MODEL PERFORMANCE\")\n",
        "print(f\"{'='*50}\")\n",
        "print(\"\\nTraining Set:\")\n",
        "print(f\"  RMSE: {train_rmse:.4f}\")\n",
        "print(f\"  MAE:  {train_mae:.4f}\")\n",
        "print(f\"  R²:   {train_r2:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "print(f\"  RMSE: {test_rmse:.4f}\")\n",
        "print(f\"  MAE:  {test_mae:.4f}\")\n",
        "print(f\"  R²:   {test_r2:.4f}\")\n",
        "\n",
        "# Feature importance (if available)\n",
        "if hasattr(final_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': final_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"TOP 10 FEATURE IMPORTANCES\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "# Sample predictions\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"SAMPLE PREDICTIONS\")\n",
        "print(f\"{'='*50}\")\n",
        "sample_results = pd.DataFrame({\n",
        "    'Actual': y_test.values[:10],\n",
        "    'Predicted': y_test_pred[:10],\n",
        "    'Difference': y_test.values[:10] - y_test_pred[:10]\n",
        "})\n",
        "print(sample_results.to_string(index=False))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf5999cc5a6a41a08a22f551b3440659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f983539d6caa47feb069dad5f842a244",
              "IPY_MODEL_41623073d2544d93992d69341794a691",
              "IPY_MODEL_f56adec3d8a14e6b89fbe1999aef08e1"
            ],
            "layout": "IPY_MODEL_1a3ba24b4c88433286023b4028297f88"
          }
        },
        "f983539d6caa47feb069dad5f842a244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1545bd04df204a769e696d267865067b",
            "placeholder": "​",
            "style": "IPY_MODEL_db87b99dcd5a4c0e934ada480264da00",
            "value": "README.md: "
          }
        },
        "41623073d2544d93992d69341794a691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558e43b91ace4aa7a5e2fc95b3d32ab6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c07091ca22fb4d229a893648ae1b7459",
            "value": 1
          }
        },
        "f56adec3d8a14e6b89fbe1999aef08e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8782032c2d4acdbbd067adff8ac42c",
            "placeholder": "​",
            "style": "IPY_MODEL_8bdac28e05a840f4ba9c880d17595b0a",
            "value": " 7.11k/? [00:00&lt;00:00, 380kB/s]"
          }
        },
        "1a3ba24b4c88433286023b4028297f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1545bd04df204a769e696d267865067b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db87b99dcd5a4c0e934ada480264da00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "558e43b91ace4aa7a5e2fc95b3d32ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c07091ca22fb4d229a893648ae1b7459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb8782032c2d4acdbbd067adff8ac42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bdac28e05a840f4ba9c880d17595b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8496d91bdd94996890e059046761b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd7113db5ba04503bb1cb07af289e868",
              "IPY_MODEL_a311dfcfee1e40cba1a35e68c4445a38",
              "IPY_MODEL_0f31111641384c21a7512ab9e1084306"
            ],
            "layout": "IPY_MODEL_e2c7f6c243d843898ef9190b769eb1c5"
          }
        },
        "bd7113db5ba04503bb1cb07af289e868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_928b8010e63f457c9b9adf4cccd982bb",
            "placeholder": "​",
            "style": "IPY_MODEL_703caed3851149c9a1c7b161e467ffc7",
            "value": "goemotions.csv: 100%"
          }
        },
        "a311dfcfee1e40cba1a35e68c4445a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39cd82e864d34d67a9f0e551dba7ed7b",
            "max": 42742250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_457d9c7933bd4010b6e077e4bc031d6e",
            "value": 42742250
          }
        },
        "0f31111641384c21a7512ab9e1084306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71387bccb3e846e494a73735752d427f",
            "placeholder": "​",
            "style": "IPY_MODEL_dac9dd532e79435ebfd77c0fae1dbea9",
            "value": " 42.7M/42.7M [11:07&lt;00:00, 67.2kB/s]"
          }
        },
        "e2c7f6c243d843898ef9190b769eb1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "928b8010e63f457c9b9adf4cccd982bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "703caed3851149c9a1c7b161e467ffc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39cd82e864d34d67a9f0e551dba7ed7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457d9c7933bd4010b6e077e4bc031d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71387bccb3e846e494a73735752d427f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac9dd532e79435ebfd77c0fae1dbea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88dc793c2e64b1583b55f7ee4b58787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_516e3218c7b74db7bc97b42f502a9096",
              "IPY_MODEL_14643316302f42e988caedb4e35e439c",
              "IPY_MODEL_c55d09a17ba2488cb02b3244e43a79c1"
            ],
            "layout": "IPY_MODEL_72100af067c4485cb7ba41fbd2421db0"
          }
        },
        "516e3218c7b74db7bc97b42f502a9096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9642c3cccbf4520b227e6f9d1379534",
            "placeholder": "​",
            "style": "IPY_MODEL_32457585b0284f1ea4ec0bdb372ca30e",
            "value": "Generating train split: 100%"
          }
        },
        "14643316302f42e988caedb4e35e439c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb88735f1a5c4c779dd10ce817eca640",
            "max": 211225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aa499cb3ae64e42ad840b38fa87363f",
            "value": 211225
          }
        },
        "c55d09a17ba2488cb02b3244e43a79c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee96a0acd8d458f8e2304b1afa73f75",
            "placeholder": "​",
            "style": "IPY_MODEL_1e191d02ca5242a7a6808a9c13e962f3",
            "value": " 211225/211225 [00:01&lt;00:00, 150197.06 examples/s]"
          }
        },
        "72100af067c4485cb7ba41fbd2421db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9642c3cccbf4520b227e6f9d1379534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32457585b0284f1ea4ec0bdb372ca30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb88735f1a5c4c779dd10ce817eca640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa499cb3ae64e42ad840b38fa87363f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ee96a0acd8d458f8e2304b1afa73f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e191d02ca5242a7a6808a9c13e962f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba0bf769a004003ae29a5632ce1949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0149aabc79cb4d6489e60e7d8898861e",
              "IPY_MODEL_76e7de9c46084eeca3102dd898719277",
              "IPY_MODEL_76ead1f0ba544d028f639d02f59f4d4e"
            ],
            "layout": "IPY_MODEL_c065b013f74240d488ceac7067757116"
          }
        },
        "0149aabc79cb4d6489e60e7d8898861e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efa6bf0871924dbe824b3eabcea7c0a3",
            "placeholder": "​",
            "style": "IPY_MODEL_a08d2e2f516c48a29e66377fd4724ebb",
            "value": "Filter: 100%"
          }
        },
        "76e7de9c46084eeca3102dd898719277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1346aefaba514dfa9d09103d17d4535a",
            "max": 211225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cda7bec0ff840e88cb7b0e6d519617b",
            "value": 211225
          }
        },
        "76ead1f0ba544d028f639d02f59f4d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68ce166e7a84f90a3621eeef2a3ca81",
            "placeholder": "​",
            "style": "IPY_MODEL_ea632be7277a4bfe9443bdb1e28f872c",
            "value": " 211225/211225 [00:05&lt;00:00, 41183.06 examples/s]"
          }
        },
        "c065b013f74240d488ceac7067757116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa6bf0871924dbe824b3eabcea7c0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08d2e2f516c48a29e66377fd4724ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1346aefaba514dfa9d09103d17d4535a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cda7bec0ff840e88cb7b0e6d519617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b68ce166e7a84f90a3621eeef2a3ca81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea632be7277a4bfe9443bdb1e28f872c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15b627640834e0da88e475ed519642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97ce76198a044c6faf1ff02da6abf653",
              "IPY_MODEL_f4d886d518db4c769b21d0ae21687e07",
              "IPY_MODEL_936a71eec0704b8b969a9a381c1456e5"
            ],
            "layout": "IPY_MODEL_25d6d91141e44ad3992be18f6bab26d6"
          }
        },
        "97ce76198a044c6faf1ff02da6abf653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0597fbc601e34176aecaf13a2285d1df",
            "placeholder": "​",
            "style": "IPY_MODEL_49146ea9eb654d53b130b0a0d56cab52",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f4d886d518db4c769b21d0ae21687e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce568197436443ef8f62ebad874dc854",
            "max": 206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9efc714fe3fb48faa39c848d656e4f6d",
            "value": 206
          }
        },
        "936a71eec0704b8b969a9a381c1456e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8badf7155c746439fd26f6a10cb1104",
            "placeholder": "​",
            "style": "IPY_MODEL_fd658d2dbaea4b5690b3f3451f7ed522",
            "value": " 206/206 [00:00&lt;00:00, 22.2kB/s]"
          }
        },
        "25d6d91141e44ad3992be18f6bab26d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0597fbc601e34176aecaf13a2285d1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49146ea9eb654d53b130b0a0d56cab52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce568197436443ef8f62ebad874dc854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9efc714fe3fb48faa39c848d656e4f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8badf7155c746439fd26f6a10cb1104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd658d2dbaea4b5690b3f3451f7ed522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bca98e96acfe4dbabc1d08ebf259f679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24d7812486824f77893a8cbe159d4da3",
              "IPY_MODEL_6a528199762f43b68d888ef1cdeb671b",
              "IPY_MODEL_4bfd1ab8aa74450885bcb92d70b5eeb8"
            ],
            "layout": "IPY_MODEL_370ac141cbbb43309f08374796422ebc"
          }
        },
        "24d7812486824f77893a8cbe159d4da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2680ec97ed444f759fbd0bc782df51a0",
            "placeholder": "​",
            "style": "IPY_MODEL_6255eb232b0c4708b47c1a7f098e427a",
            "value": "config.json: 100%"
          }
        },
        "6a528199762f43b68d888ef1cdeb671b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380974a7cb914658a08c936fab68f80e",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2da58f7b82154fb586b4e519802e290f",
            "value": 411
          }
        },
        "4bfd1ab8aa74450885bcb92d70b5eeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbf76576004489d81cd38bcae8336e5",
            "placeholder": "​",
            "style": "IPY_MODEL_042639933b8e49388bed02ebe0db8c00",
            "value": " 411/411 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "370ac141cbbb43309f08374796422ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2680ec97ed444f759fbd0bc782df51a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6255eb232b0c4708b47c1a7f098e427a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "380974a7cb914658a08c936fab68f80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da58f7b82154fb586b4e519802e290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fbf76576004489d81cd38bcae8336e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "042639933b8e49388bed02ebe0db8c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1970b04f125d4b1181732c9165d5f37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e98ed06bc4514f3fab02c738beb16c8c",
              "IPY_MODEL_c86e273ab1de4706b2ea24b72bc8cde9",
              "IPY_MODEL_c61ab01a81d7444b9b76ec292714d37f"
            ],
            "layout": "IPY_MODEL_f43d1173141b42738c0ab85afc213476"
          }
        },
        "e98ed06bc4514f3fab02c738beb16c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40903222ddcd4c5aab87103177c1cb27",
            "placeholder": "​",
            "style": "IPY_MODEL_ca35089dc9c3475a97223e03bf3da74b",
            "value": "vocab.txt: "
          }
        },
        "c86e273ab1de4706b2ea24b72bc8cde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64919fba2fc246ca99e8c9188d959c30",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59470828b28744319faf140424043b7b",
            "value": 1
          }
        },
        "c61ab01a81d7444b9b76ec292714d37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66640cd3e2844c3cbd759441990f682c",
            "placeholder": "​",
            "style": "IPY_MODEL_606e3f202de2463f88016a5fa394dffa",
            "value": " 3.16M/? [00:00&lt;00:00, 58.8MB/s]"
          }
        },
        "f43d1173141b42738c0ab85afc213476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40903222ddcd4c5aab87103177c1cb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca35089dc9c3475a97223e03bf3da74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64919fba2fc246ca99e8c9188d959c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "59470828b28744319faf140424043b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66640cd3e2844c3cbd759441990f682c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606e3f202de2463f88016a5fa394dffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891b8499347e45fc95823c923480fe0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f09373f091c0498b8cdd2e10e6aeeb63",
              "IPY_MODEL_560d670e55074cf3bcea53063668ac22",
              "IPY_MODEL_2781542c38b240cf9c5a46111fae5bcf"
            ],
            "layout": "IPY_MODEL_690566a3e7234ae68db4a81c65989be2"
          }
        },
        "f09373f091c0498b8cdd2e10e6aeeb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e5ff04b7bd40be966833012899c80d",
            "placeholder": "​",
            "style": "IPY_MODEL_df2bdf424ee347a38ce1543583e7de81",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "560d670e55074cf3bcea53063668ac22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d158a77b24c448d2b8d34a8724686624",
            "max": 113,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b9e80c3ed3442eca3f539a853f62d23",
            "value": 113
          }
        },
        "2781542c38b240cf9c5a46111fae5bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe4d1fe402b4eb980a6f052e95f71a6",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd541fccb794449b489d23471bc4bb9",
            "value": " 113/113 [00:00&lt;00:00, 8.10kB/s]"
          }
        },
        "690566a3e7234ae68db4a81c65989be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5e5ff04b7bd40be966833012899c80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2bdf424ee347a38ce1543583e7de81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d158a77b24c448d2b8d34a8724686624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9e80c3ed3442eca3f539a853f62d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fe4d1fe402b4eb980a6f052e95f71a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd541fccb794449b489d23471bc4bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2a9e8b2ca1f4bbea76fdc75823ae49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e12f20e6d2c415f8e0aebefd66dcbef",
              "IPY_MODEL_60fadf16bc0e48deaa8d4c1f50b0a77f",
              "IPY_MODEL_58561ef2f3d74917a8dd1a2ecf51e813"
            ],
            "layout": "IPY_MODEL_8bf4bc245c6e464894392b5c0d25d1d8"
          }
        },
        "3e12f20e6d2c415f8e0aebefd66dcbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0b3be5bdbe461ea29d445b9cfc5944",
            "placeholder": "​",
            "style": "IPY_MODEL_bd80ffcbbba949528a0813b022de807e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "60fadf16bc0e48deaa8d4c1f50b0a77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84040b32ed2a46698165158dc117d4a1",
            "max": 953477430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26bffcae51ed4761a22d6597f265ce26",
            "value": 953477430
          }
        },
        "58561ef2f3d74917a8dd1a2ecf51e813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb7cbb00fb445b1997d6cc3386c8527",
            "placeholder": "​",
            "style": "IPY_MODEL_53dfb567c04e437c82e0758aac87892f",
            "value": " 953M/953M [2:20:47&lt;00:00, 6.87kB/s]"
          }
        },
        "8bf4bc245c6e464894392b5c0d25d1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc0b3be5bdbe461ea29d445b9cfc5944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd80ffcbbba949528a0813b022de807e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84040b32ed2a46698165158dc117d4a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bffcae51ed4761a22d6597f265ce26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebb7cbb00fb445b1997d6cc3386c8527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dfb567c04e437c82e0758aac87892f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545bd949cef54a48be54536fffacaa61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fc847d3f6f34de1936fca4488259a85",
              "IPY_MODEL_167e8601f6834da9b254385dfd6521e9",
              "IPY_MODEL_98cb29694be7400c99f46cfa8eb5b83c"
            ],
            "layout": "IPY_MODEL_77972b5026804518ae2d5f51c659d4de"
          }
        },
        "9fc847d3f6f34de1936fca4488259a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b58e1d640c94af1807e2dd07702f340",
            "placeholder": "​",
            "style": "IPY_MODEL_779e04b27c004dcc8e2c178c5e4b46be",
            "value": "model.safetensors:   0%"
          }
        },
        "167e8601f6834da9b254385dfd6521e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c9219170684369af10bf9856e7cbf3",
            "max": 953416988,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67bb65e3fdb04586967a5a65141235bb",
            "value": 0
          }
        },
        "98cb29694be7400c99f46cfa8eb5b83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589b818830b04512bbe348f490d1ebb6",
            "placeholder": "​",
            "style": "IPY_MODEL_afaf02a0409a41fb85d9d2afe94ec210",
            "value": " 0.00/953M [00:00&lt;?, ?B/s]"
          }
        },
        "77972b5026804518ae2d5f51c659d4de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b58e1d640c94af1807e2dd07702f340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779e04b27c004dcc8e2c178c5e4b46be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c9219170684369af10bf9856e7cbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bb65e3fdb04586967a5a65141235bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "589b818830b04512bbe348f490d1ebb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afaf02a0409a41fb85d9d2afe94ec210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a938ed94c44e10870563b2047868de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3c4bda368a8408999498a63f72ff2cf",
              "IPY_MODEL_963365977bc24a5ab660839c6e22f0cd",
              "IPY_MODEL_cce270112fe4478b9bb662d6d7ef17e8"
            ],
            "layout": "IPY_MODEL_330aef3364bb4ba78d549d7ad49dd0ba"
          }
        },
        "c3c4bda368a8408999498a63f72ff2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9278fb5f3cb4cb2bcb31b2316461f17",
            "placeholder": "​",
            "style": "IPY_MODEL_4677acebb0b641a3845dff0cc502fc21",
            "value": "Best trial: 50. Best value: 1.76971e-08: 100%"
          }
        },
        "963365977bc24a5ab660839c6e22f0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0e13e8660147548d142b7fa144ddd6",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad64b755ce9947c4b77ee721e477e37a",
            "value": 100
          }
        },
        "cce270112fe4478b9bb662d6d7ef17e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704fd368f58c42bf8ce6a7996f1ea0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_e4cea9cc6ad44bc09a265724cbd7df74",
            "value": " 100/100 [01:10&lt;00:00,  7.42it/s]"
          }
        },
        "330aef3364bb4ba78d549d7ad49dd0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9278fb5f3cb4cb2bcb31b2316461f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4677acebb0b641a3845dff0cc502fc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc0e13e8660147548d142b7fa144ddd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad64b755ce9947c4b77ee721e477e37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "704fd368f58c42bf8ce6a7996f1ea0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4cea9cc6ad44bc09a265724cbd7df74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}